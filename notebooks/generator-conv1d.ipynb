{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# scientific\n",
    "import numpy as np\n",
    "\n",
    "import beatbrain\n",
    "from beatbrain import utils\n",
    "\n",
    "# visualization\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Lambda, Reshape, Layer\n",
    "from tensorflow.keras.callbacks import (\n",
    "    Callback,\n",
    "    TensorBoard,\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TerminateOnNaN,\n",
    "    CSVLogger,\n",
    "    LambdaCallback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "DATA_ROOT = Path(\"../data/fma/image\")\n",
    "TEST_SPLIT = 0.2\n",
    "SUBSET = 5\n",
    "PARALLEL=False\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_DIMS = [512, 640, 1]\n",
    "BATCH_SIZE = 1\n",
    "LATENT_DIM = 256\n",
    "EPOCHS = 2\n",
    "NUM_CONV = 3\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Output\n",
    "EXAMPLES_TO_GENERATE = 16\n",
    "INTERPOLATION_POINTS = 9\n",
    "OUTPUT_DIR = Path(\"../data/output/images\")\n",
    "MODEL_PATH = Path(\"model.h5\")\n",
    "TENSORBOARD_DIR = Path('tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input type(s) in \u001b[33m'/home/cds_data/fma/image/train'\u001b[39m...\n",
      "Determined input type to be \u001b[36m'IMAGE'\u001b[39m\n",
      "Checking input type(s) in \u001b[33m'/home/cds_data/fma/image/val'\u001b[39m...\n",
      "Determined input type to be \u001b[36m'IMAGE'\u001b[39m\n",
      "Checking input type(s) in \u001b[33m'/home/cds_data/fma/image/test'\u001b[39m...\n",
      "Determined input type to be \u001b[36m'IMAGE'\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"train\", batch_size=BATCH_SIZE, parallel=False\n",
    ")\n",
    "val_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"val\", batch_size=BATCH_SIZE, parallel=False,\n",
    ")\n",
    "test_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"test\", batch_size=1, parallel=False, shuffle_buffer=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 640, 1)\n",
      "(1, 512, 640, 1)\n",
      "(1, 512, 640, 1)\n",
      "(1, 512, 640, 1)\n",
      "(1, 512, 640, 1)\n",
      "CPU times: user 384 ms, sys: 177 ms, total: 560 ms\n",
      "Wall time: 559 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in train_dataset.take(SUBSET):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cvae(latent_dim, input_shape, num_conv=2, batch_size=1, learning_rate=1e-4):\n",
    "    def reparam(args):\n",
    "        z_mean, z_log_var = args\n",
    "        dim = tf.keras.backend.int_shape(z_mean)[1]\n",
    "        eps = tf.keras.backend.random_normal(shape=(batch_size, dim))\n",
    "        return eps * tf.exp(z_log_var * .5) + z_mean\n",
    "    \n",
    "    def reshape_1d(x):\n",
    "        x = tf.squeeze(x, axis=-1)\n",
    "        x = tf.transpose(x, [0, 2, 1])\n",
    "        return x\n",
    "    \n",
    "    def reshape_2d(x):\n",
    "        x = tf.transpose(x, [0, 2, 1])\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        return x\n",
    "    \n",
    "    class Conv1DTranspose(Layer):\n",
    "        def __init__(self, filters, kernel_size, strides=1, *args, **kwargs):\n",
    "            self._filters = filters\n",
    "            print(self._filters)\n",
    "            self._kernel_size = (1, kernel_size)\n",
    "            self._strides = (1, strides)\n",
    "            self._args, self._kwargs = args, kwargs\n",
    "            super(Conv1DTranspose, self).__init__()\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            self._model = Sequential()\n",
    "            self._model.add(Lambda(reshape_2d, batch_input_shape=input_shape))\n",
    "            self._model.add(Conv2DTranspose(self._filters,\n",
    "                                            kernel_size=self._kernel_size,\n",
    "                                            strides=self._strides,\n",
    "                                            *self._args, **self._kwargs))\n",
    "            self._model.add(Lambda(lambda x: x[:,0]))\n",
    "            self._model.summary()\n",
    "            super(Conv1DTranspose, self).build(input_shape)\n",
    "\n",
    "        def call(self, x):\n",
    "            return self._model(x)\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return self._model.compute_output_shape(input_shape)\n",
    "\n",
    "#     def conv1d_transpose(args):\n",
    "#         d, conv1d_param = args\n",
    "#         print(d.shape)\n",
    "#         input_filter_size, output_filter_size, kernel_size, strides = conv1d_param\n",
    "#         filters = tf.Variable(tf.random.normal((kernel_size, output_filter_size, input_filter_size))) # (filter width, output_channels, input_channels)\n",
    "#         decoder_output = tf.nn.conv1d_transpose(d,\n",
    "#             output_shape=tf.constant([np.ceil(d.shape[1]/float(strides)), d.shape[2]]),\n",
    "#             filters=filters,\n",
    "#             strides=strides,\n",
    "#             padding='SAME',\n",
    "#         )\n",
    "#         return decoder_output\n",
    "    \n",
    "    encoder_input = tf.keras.Input(shape=input_shape, batch_size=batch_size)\n",
    "    e = tf.keras.layers.Lambda(reshape_1d)(encoder_input) # (batch_size, time, freq)\n",
    "    e = tf.keras.layers.Conv1D(filters=3, kernel_size=3, strides=2, padding='SAME', activation='relu')(e) # (batch_size, time, filter_size)\n",
    "\n",
    "    for i in range(num_conv):\n",
    "        e = tf.keras.layers.Conv1D(filters=6, kernel_size=3, strides=2, padding='SAME', activation='relu')(e) # (batch_size, time, filter_size)\n",
    "    \n",
    "    decoder_input_shape = tf.keras.backend.int_shape(e)\n",
    "    e = tf.keras.layers.Flatten()(e)\n",
    "    e = tf.keras.layers.Dense(latent_dim*2)(e) # (batch_size, latent_dim*2)\n",
    "    z_mean = tf.keras.layers.Dense(latent_dim)(e)\n",
    "    z_log_var = tf.keras.layers.Dense(latent_dim)(e)\n",
    "    z = tf.keras.layers.Lambda(reparam, output_shape=(latent_dim, ))([z_mean, z_log_var]) # (batch_size, latent_dim)\n",
    "    encoder = tf.keras.Model(encoder_input, [z_mean, z_log_var, z], name=\"Encoder\")\n",
    "\n",
    "#     decoder_input_shape = (batch_size, \n",
    "#         input_shape[0] // (2 ** (num_conv + 1)),\n",
    "#         input_shape[1] // (2 ** (num_conv + 1)),\n",
    "#         64\n",
    "#     )\n",
    "    # (decoder_input_shape): (32, 40, 64)\n",
    "\n",
    "    decoder_input = tf.keras.Input(shape=(latent_dim, ))\n",
    "    d = tf.keras.layers.Dense(\n",
    "        decoder_input_shape[1] * decoder_input_shape[2],\n",
    "        activation=tf.nn.relu,\n",
    "    )(decoder_input)\n",
    "\n",
    "    \n",
    "    d = tf.keras.layers.Reshape(\n",
    "        target_shape=(\n",
    "            decoder_input_shape[1],\n",
    "            decoder_input_shape[2],\n",
    "            )\n",
    "    )(d)\n",
    "    \n",
    "    # d.shape: (None, 31, 39, 64)\n",
    "    for i in range(num_conv):\n",
    "#         d = tf.keras.layers.Conv1DTranspose(\n",
    "#             filters=decoder_input_shape[2],\n",
    "#             kernel_size=3,\n",
    "#             strides=2,\n",
    "#             padding='SAME',\n",
    "#             activation='relu',\n",
    "#         )(d)\n",
    "#         d = tf.keras.layers.Lambda(conv1d_transpose)([d, [decoder_input_shape[2], decoder_input_shape[2], 3, 2]]) # input_filter_size, output_filter_size, kernel_size, strides\n",
    "    \n",
    "#     d = tf.keras.layers.Lambda(conv1d_transpose)([d, [decoder_input_shape[2], decoder_input_shape[2], 3, 2]])\n",
    "        d = Conv1DTranspose(filters=input_shape[0]*2, kernel_size=3, strides=2, padding='SAME', activation='relu')(d)\n",
    "    d = Conv1DTranspose(filters=input_shape[0]*2, kernel_size=3, strides=2, padding='SAME', activation='relu')(d)\n",
    "    decoder_output = Conv1DTranspose(filters=input_shape[0], kernel_size=3, strides=1, padding='SAME', activation='relu')(d)\n",
    "    decoder_output = tf.keras.layers.Lambda(reshape_2d)(decoder_output)\n",
    "    decoder = tf.keras.Model(decoder_input, decoder_output, name=\"Decoder\")    \n",
    "    outputs = decoder(encoder(encoder_input)[2])\n",
    "    d = tf.keras.layers.Lambda(reshape_2d)(d)\n",
    "    model = tf.keras.Model(encoder_input, outputs, name=\"VAE\")\n",
    "    \n",
    "    assert (encoder_input.shape == outputs.shape)\n",
    "    reconstruction_loss = tf.losses.mse(encoder_input, outputs)\n",
    "    reconstruction_loss = tf.reduce_sum(reconstruction_loss, axis=[1, 2])\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, z_mean, z_log_var)\n",
    "    kl_loss = logqz_x - logpz\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    model.add_loss(vae_loss)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "    return model, encoder, decoder\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis\n",
    "    )\n",
    "\n",
    "@tf.function\n",
    "def sample(latent_dim, decoder, eps=None):\n",
    "    if eps is None:\n",
    "        eps = tf.random.normal(shape=(100, latent_dim))\n",
    "    return decode(decoder, eps, apply_sigmoid=True)\n",
    "\n",
    "\n",
    "def encode(encoder, x):\n",
    "    inference = encoder(x)\n",
    "    mean, logvar = tf.split(inference, num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "\n",
    "def reparameterize(mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "\n",
    "def decode(decoder, z, apply_sigmoid=False):\n",
    "    logits = decoder(z)\n",
    "    if apply_sigmoid:\n",
    "        probs = tf.sigmoid(logits)\n",
    "        return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(encoder, decoder, x):\n",
    "    mean, logvar = encoder(x)\n",
    "    z = reparameterize(mean, logvar)\n",
    "    x_logit = decoder(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3]) # reconstruction\n",
    "    logpz = log_normal_pdf(z, 0., 0.) # kl divergence loss 1 term\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar) # kl divergence loss term\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "@tf.function\n",
    "def compute_apply_gradients(model, encoder, decoder, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(encoder, decoder, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_10 (Lambda)           (None, 6, 40, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 6, 80, 1024)       4096      \n",
      "_________________________________________________________________\n",
      "lambda_11 (Lambda)           (None, 80, 1024)          0         \n",
      "=================================================================\n",
      "Total params: 4,096\n",
      "Trainable params: 4,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1024\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_12 (Lambda)           (None, 1024, 80, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 1024, 160, 1024)   4096      \n",
      "_________________________________________________________________\n",
      "lambda_13 (Lambda)           (None, 160, 1024)         0         \n",
      "=================================================================\n",
      "Total params: 4,096\n",
      "Trainable params: 4,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1024\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_14 (Lambda)           (None, 1024, 160, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 1024, 320, 1024)   4096      \n",
      "_________________________________________________________________\n",
      "lambda_15 (Lambda)           (None, 320, 1024)         0         \n",
      "=================================================================\n",
      "Total params: 4,096\n",
      "Trainable params: 4,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1024\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_16 (Lambda)           (None, 1024, 320, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 1024, 640, 1024)   4096      \n",
      "_________________________________________________________________\n",
      "lambda_17 (Lambda)           (None, 640, 1024)         0         \n",
      "=================================================================\n",
      "Total params: 4,096\n",
      "Trainable params: 4,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "512\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_18 (Lambda)           (None, 1024, 640, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 1024, 640, 512)    2048      \n",
      "_________________________________________________________________\n",
      "lambda_19 (Lambda)           (None, 640, 512)          0         \n",
      "=================================================================\n",
      "Total params: 2,048\n",
      "Trainable params: 2,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Output Decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to Decoder.\n",
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(1, 512, 640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (Model)                 [(1, 256), (1, 256), 390947      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (Model)                 multiple             80112       Encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (1, 640, 512)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (1, 320, 3)          4611        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (1, 160, 6)          60          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (1, 80, 6)           114         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (1, 40, 6)           114         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (1, 240)             0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (1, 512)             123392      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (1, 256)             131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (1, 256)             131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (1, 256)             0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_4 (TensorFlowOp [(1, 256)]           0           lambda_5[0][0]                   \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_1 (TensorFlowOp [(1, 256)]           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_3 (TensorFlowOp [(1, 256)]           0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow_3 (TensorFlowOp [(1, 256)]           0           tf_op_layer_sub_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_1 (TensorFlowOp [(1, 256)]           0           tf_op_layer_Neg_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow_2 (TensorFlowOp [(1, 256)]           0           tf_op_layer_sub_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_6 (TensorFlowOp [(1, 256)]           0           tf_op_layer_pow_3[0][0]          \n",
      "                                                                 tf_op_layer_Exp_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_4 (TensorFlowOp [(1, 256)]           0           tf_op_layer_pow_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_7 (TensorFlowOp [(1, 256)]           0           tf_op_layer_mul_6[0][0]          \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_5 (TensorFlowOp [(1, 256)]           0           tf_op_layer_mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_8 (TensorFlowOp [(1, 256)]           0           tf_op_layer_add_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_6 (TensorFlowOp [(1, 256)]           0           tf_op_layer_add_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SquaredDifference_1 [(1, 512, 640, 1)]   0           Decoder[1][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_7 (TensorFlowOp [(1, 256)]           0           tf_op_layer_add_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_5 (TensorFlowOp [(1, 256)]           0           tf_op_layer_add_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [(1, 512, 640)]      0           tf_op_layer_SquaredDifference_1[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_5 (TensorFlowOp [(1,)]               0           tf_op_layer_mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_4 (TensorFlowOp [(1,)]               0           tf_op_layer_mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(1,)]               0           tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_5 (TensorFlowOp [(1,)]               0           tf_op_layer_Sum_5[0][0]          \n",
      "                                                                 tf_op_layer_Sum_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_9 (TensorFlowOp [(1,)]               0           tf_op_layer_Sum_3[0][0]          \n",
      "                                                                 tf_op_layer_sub_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_3 (TensorFlowO [()]                 0           tf_op_layer_add_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_1 (AddLoss)            ()                   0           tf_op_layer_Mean_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 471,059\n",
      "Trainable params: 471,059\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(shape=[EXAMPLES_TO_GENERATE, LATENT_DIM])\n",
    "model, encoder, decoder = build_cvae(LATENT_DIM, IMAGE_DIMS, num_conv=NUM_CONV, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,1024,1024,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput] name: VAE/Decoder/conv1d_transpose_7/sequential_7/conv2d_transpose_7/conv2d_transpose/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-11bf2541e671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     tf.keras.callbacks.TensorBoard(\n\u001b[1;32m      8\u001b[0m         \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTENSORBOARD_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mupdate_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m ])\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-381785e9f160>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[0;34m(x, kernel, output_shape, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   4925\u001b[0m     x = nn.conv2d_transpose(x, kernel, output_shape, strides,\n\u001b[1;32m   4926\u001b[0m                             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4927\u001b[0;31m                             data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   4928\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4929\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[0;34m(value, filter, output_shape, strides, padding, data_format, name, input, filters, dilations)\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_transpose_v2\u001b[0;34m(input, filters, output_shape, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2273\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2275\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1370\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/krishna/anaconda3/envs/ai/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,1024,1024,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput] name: VAE/Decoder/conv1d_transpose_7/sequential_7/conv2d_transpose_7/conv2d_transpose/"
     ]
    }
   ],
   "source": [
    "# single_sample = utils.load_image('../data/fma/image/000/000002/0.exr')\n",
    "# single_sample = train_dataset.reshape(1, *single_sample.shape, 1)\n",
    "# model.fit(single_sample, epochs=EPOCHS, validation_data=(single_sample, None))\n",
    "\n",
    "# model.fit_generator(train_dataset, epochs=EPOCHS, validation_data=test_dataset)\n",
    "model.fit_generator(train_dataset, epochs=EPOCHS, callbacks=[\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=TENSORBOARD_DIR / str(int(time.time())),\n",
    "        update_freq=100,\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset\n",
    "\n",
    "beatbrain.display.show_spec(utils.denormalize_spectrogram(sample[0, ..., 0]), title=\"Orginal\")\n",
    "plt.show()\n",
    "sns.distplot(train_dataset.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(train_dataset)\n",
    "beatbrain.display.show_spec(utils.denormalize_spectrogram(model(sample)[0, ..., 0].numpy()), title=\"Predicted\")\n",
    "plt.show()\n",
    "sns.distplot(model(train_dataset).numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 4096\n",
    "HOP_LENGTH = 256\n",
    "SAMPLE_RATE = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_recon = utils.spectrogram_to_audio(sample[0, ..., 0], denormalize=True, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(sample_recon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_recon = utils.spectrogram_to_audio(prediction[0, ..., 0], denormalize=True, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(prediction_recon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(decoder, epoch, test_input):\n",
    "    num_plots = math.ceil(math.sqrt(len(test_input)))\n",
    "    predictions = sample(LATENT_DIM, decoder, eps=test_input)\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    for i, pred in enumerate(predictions):\n",
    "        plt.subplot(num_plots, num_plots, i + 1)\n",
    "        plt.imshow(pred[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        plt.axis('off')\n",
    "        output_dir = os.path.join(OUTPUT_DIR, 'progress', str(i))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        image = Image.fromarray(pred[:, :, 0].numpy(), mode='F')\n",
    "#         image.save(os.path.join(output_dir, f\"epoch_{epoch}.tiff\"))\n",
    "        image.save(os.path.join(output_dir, f\"spec.tiff\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import librosa\n",
    "\n",
    "SR = 32768\n",
    "N_FFT = 4096\n",
    "N_MELS = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 5\n",
    "A = \"../data/fma/audio/000002.mp3\"\n",
    "B = \"../data/fma/audio/000005.mp3\"\n",
    "\n",
    "interp_dir = Path(f\"interpolation/{int(time())}\")\n",
    "interp_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "x, _ = librosa.load(A, sr=SR, duration=DURATION)\n",
    "y, _ = librosa.load(B, sr=SR, duration=DURATION)\n",
    "x = librosa.feature.melspectrogram(x, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "y = librosa.feature.melspectrogram(y, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "x, y = x[0, None], y[None, :, None]\n",
    "print(x.shape)\n",
    "x_mean, x_logvar = model.encode(x)\n",
    "y_mean, y_logvar = model.encode(y)\n",
    "\n",
    "# Reconstruction\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "x_recon = model.sample(model.reparameterize(x_mean, x_logvar))\n",
    "plt.imshow(x_recon[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Interpolation\n",
    "fractions = np.linspace(0, 1, num=INTERPOLATION_POINTS)[:, None]\n",
    "means = (x_mean * (1 - fractions)) + (y_mean * fractions)  # Interpolated latent vectors\n",
    "logvars = (x_logvar * (1 - fractions)) + (y_logvar * fractions)  # Interpolated latent vectors\n",
    "points = model.reparameterize(means, logvars)\n",
    "interpolated = model.sample(points)\n",
    "\n",
    "num_plots = math.ceil(math.sqrt(INTERPOLATION_POINTS))\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace=0, wspace=0.03)\n",
    "for i, pred in enumerate(interpolated):\n",
    "    Image.fromarray(pred[:, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'{i}.tiff'))\n",
    "    plt.subplot(num_plots, num_plots, i + 1)\n",
    "    if i == 0:\n",
    "        Image.fromarray(x[0, :, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'a.tiff'))\n",
    "        plt.imshow(x[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    elif i == INTERPOLATION_POINTS - 1:\n",
    "        Image.fromarray(y[0, :, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'b.tiff'))\n",
    "        plt.imshow(y[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    else:\n",
    "        plt.imshow(pred[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig(interp_dir.joinpath('interpolation.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, num_conv=2, input_shape=(*IMAGE_DIMS, WINDOW_SIZE)):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.inference_net = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32, kernel_size=3, strides=(2, 2), activation='relu',\n",
    "                ),\n",
    "                *[tf.keras.layers.Conv2D(\n",
    "                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'\n",
    "                ) for i in range(num_conv)],\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(2 * latent_dim)\n",
    "            ], name=\"Encoder\"\n",
    "        )\n",
    "\n",
    "        decoder_input_shape = (\n",
    "            input_shape[0] // (2 ** (num_conv + 1)),\n",
    "            input_shape[1] // (2 ** (num_conv + 1)),\n",
    "            64\n",
    "        )\n",
    "\n",
    "        self.generative_net = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim, )),\n",
    "                tf.keras.layers.Dense(\n",
    "                    decoder_input_shape[0] * decoder_input_shape[1] * decoder_input_shape[2],\n",
    "                    activation=tf.nn.relu\n",
    "                ),\n",
    "                tf.keras.layers.Reshape(target_shape=(decoder_input_shape[0], \n",
    "                                                      decoder_input_shape[1], decoder_input_shape[2])),\n",
    "                *[tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding='SAME',\n",
    "                    activation='relu'\n",
    "                ) for i in range(num_conv)],\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding='SAME',\n",
    "                    activation='relu'\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, kernel_size=3, strides=(1, 1), padding='SAME'\n",
    "                )\n",
    "            ], name=\"Decoder\"\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        inference = self.inference_net(x)\n",
    "        mean, logvar = tf.split(inference, num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.generative_net(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(LATENT_DIM, num_conv=NUM_CONV,)\n",
    "model.inference_net.summary()\n",
    "model.generative_net.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
