{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mel spec demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from natsort import natsorted\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import scipy\n",
    "import librosa\n",
    "# from skimage.transform import resize\n",
    "from beatbrain.metrics import ncc\n",
    "from beatbrain import utils\n",
    "\n",
    "# Visualization\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from beatbrain.display import show_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_audio(audio, **kwargs):\n",
    "    ipd.display(ipd.Audio(audio, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_PATH = \"home/pengfei/yunyi/beatbrain/data/fma/audio/test/006/006329.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUDIO_PATH = \"../data/fma/audio/000/000005.mp3\"\n",
    "START = 0\n",
    "DURATION = 5\n",
    "SAMPLE_RATE = 32768\n",
    "N_FFT = 4096\n",
    "HOP_LENGTH = 256\n",
    "N_MELS = 512\n",
    "CHUNK_SIZE = 640\n",
    "RESAMPLE_TYPE = 'kaiser_fast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(AUDIO_PATH, sr=SAMPLE_RATE,\n",
    "                         offset=START, duration=DURATION,\n",
    "                         res_type=RESAMPLE_TYPE)\n",
    "show_audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.abs(librosa.stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH))\n",
    "show_spec(spec, scale_fn=librosa.amplitude_to_db, title=\"STFT Spectrogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing \n",
    "### get genre labels from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#home/pengfei/yunyi/beatbrain/data/fma/numpy\n",
    "#metadata = Path(\"/home/cds_data/fma/metadata\")\n",
    "metadata = Path(\"/home/pengfei/yunyi/beatbrain/data/fma/metadata\")\n",
    "tracks = pd.read_csv(metadata.joinpath('tracks.csv'), header=[0, 1, 2])\n",
    "tracks = tracks.droplevel(2, axis=1)\n",
    "tracks.columns = tracks.columns.set_levels(['track_id', *tracks.columns.levels[0][1:]], level=0)\n",
    "tracks.columns = tracks.columns.set_levels(['', *tracks.columns.levels[1][1:]], level=1)\n",
    "tracks.set_index(\"track_id\", inplace=True)\n",
    "tracks = tracks[tracks[\"set\", \"subset\"] == \"small\"]  # Only include songs from fma_small dataset\n",
    "tracks = tracks[pd.notnull(tracks[\"track\", \"genre_top\"])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples, 800 validation examples, 800 testing examples\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks=tracks.drop(['album', 'artist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Electronic',\n",
       " 'Experimental',\n",
       " 'Folk',\n",
       " 'Hip-Hop',\n",
       " 'Instrumental',\n",
       " 'International',\n",
       " 'Pop',\n",
       " 'Rock'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tracks['track', 'genre_top'])#8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "10\n",
      "2\n",
      "140\n",
      "10250\n",
      "1482\n",
      "666\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "### get one excerpt per category\n",
    "for i in set(set(tracks['track', 'genre_top'])):\n",
    "    print(tracks[tracks['track', 'genre_top']==i].head(1).index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep GMM (kmeans init)\n",
    "##### one excerpt per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2\n",
      "666\n",
      "182\n",
      "140\n",
      "148\n",
      "10250\n",
      "1482\n"
     ]
    }
   ],
   "source": [
    "example_ls=[666,10250,182,10,140,148,1482,2]\n",
    "import numpy as np\n",
    "X_mean=[]\n",
    "#Y=[]\n",
    "for fpath in glob.glob('/home/pengfei/yunyi/beatbrain/data/fma/numpy/*/*'):\n",
    "    track_id=int(fpath[-10:-4])\n",
    "    if track_id in example_ls:\n",
    "        print(track_id)\n",
    "        example_ls.remove(track_id)\n",
    "        nps=utils.load_arrays(fpath)\n",
    "        #only take the first\n",
    "        f1=np.mean(nps[0],axis=1)\n",
    "        f2=np.std(nps[0], axis=1)\n",
    "        f3=np.median(nps[0],axis=1)\n",
    "        npz=np.concatenate((f1,f2,f3), axis=None)\n",
    "        X_mean.append(npz)\n",
    "X_mean=np.array(X_mean)\n",
    "np.save('X_example.npy', X_mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1536)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 640)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz=utils.load_arrays(\"/home/pengfei/yunyi/beatbrain/data/fma/numpy/000/000002.npz\")\n",
    "npz[-1].shape#(band,time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep ML X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "##########prep data#########################\n",
    "X=[]\n",
    "Y=[]\n",
    "####normalize\n",
    "#_min,_max=float('inf'),-float('inf')\n",
    "\n",
    "#for fpath in glob.glob('/home/cds_data/fma/numpy/*/*'):\n",
    "for fpath in glob.glob('home/pengfei/yunyi/beatbrain/data/fma/numpy/*/*'):\n",
    "    #based on track_id get test/val/train\n",
    "    track_id=int(fpath[-10:-4])\n",
    "    ########use fma predefined split####\n",
    "    #split=tracks.loc[track_id][\"set\"][\"split\"]\n",
    "    genre=tracks.loc[track_id][\"track\"][\"genre_top\"]\n",
    "    #load data\n",
    "    nps=utils.load_arrays(fpath)\n",
    "    for npz in nps:\n",
    "        #mean\n",
    "        f1=np.mean(npz,axis=1)\n",
    "        #median\n",
    "        f2=np.std(npz, axis=1)\n",
    "        #std\n",
    "        f3=np.median(npz,axis=1)\n",
    "        #append \n",
    "        npz=np.concatenate((f1,f2,f3), axis=None)\n",
    "        X.append(npz)\n",
    "        Y.append(genre)\n",
    "        ###########normalize code(unused)\n",
    "        #_min=min(np.amin(np),_min)\n",
    "        #_max=max(np.amix(np),_max)\n",
    "#prep all data\n",
    "X,Y=np.array(X),np.array(Y)\n",
    "#####normalize(unused)\n",
    "#X=(X-_min)/(_max-_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change y to categorical int\n",
    "lookupTable, Y = np.unique(Y, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_all_1.npy', X) # save\n",
    "np.save('Y_all_1.npy', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained ML X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########load from local if pre##############\n",
    "X=np.load(\"X_all_1.npy\")\n",
    "Y=np.load(\"Y_all_1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43323, 1536) (43323,)\n",
      "{(1536,)}\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)\n",
    "print(set([X[i].shape for i in range(len(X))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X[:10000],Y[:10000],test_size=0.3,random_state=0)\n",
    "X_train, X_test, y_train, y_test = X[:10000],X[10000:12000],Y[:10000],Y[10000:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1536), (2000, 1536), (10000,), (2000,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min leaves=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.22      0.24       297\n",
      "           1       0.29      0.24      0.26       401\n",
      "           2       0.22      0.38      0.28       146\n",
      "           3       0.25      0.16      0.20       277\n",
      "           4       0.18      0.40      0.25       134\n",
      "           5       0.28      0.16      0.20       312\n",
      "           6       0.14      0.14      0.14       304\n",
      "           7       0.26      0.42      0.32       129\n",
      "\n",
      "    accuracy                           0.23      2000\n",
      "   macro avg       0.24      0.27      0.24      2000\n",
      "weighted avg       0.24      0.23      0.23      2000\n",
      "\n",
      "min leaves=3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.28      0.27       297\n",
      "           1       0.30      0.27      0.28       401\n",
      "           2       0.20      0.33      0.25       146\n",
      "           3       0.21      0.15      0.17       277\n",
      "           4       0.20      0.42      0.27       134\n",
      "           5       0.28      0.12      0.17       312\n",
      "           6       0.15      0.14      0.15       304\n",
      "           7       0.30      0.42      0.35       129\n",
      "\n",
      "    accuracy                           0.24      2000\n",
      "   macro avg       0.24      0.27      0.24      2000\n",
      "weighted avg       0.24      0.24      0.23      2000\n",
      "\n",
      "min leaves=5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.26      0.27       297\n",
      "           1       0.29      0.26      0.27       401\n",
      "           2       0.19      0.32      0.24       146\n",
      "           3       0.23      0.17      0.20       277\n",
      "           4       0.19      0.41      0.26       134\n",
      "           5       0.26      0.14      0.18       312\n",
      "           6       0.15      0.14      0.15       304\n",
      "           7       0.30      0.40      0.35       129\n",
      "\n",
      "    accuracy                           0.23      2000\n",
      "   macro avg       0.24      0.26      0.24      2000\n",
      "weighted avg       0.24      0.23      0.23      2000\n",
      "\n",
      "min leaves=7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.24      0.25       297\n",
      "           1       0.30      0.26      0.28       401\n",
      "           2       0.21      0.32      0.26       146\n",
      "           3       0.25      0.21      0.23       277\n",
      "           4       0.18      0.40      0.25       134\n",
      "           5       0.22      0.14      0.17       312\n",
      "           6       0.18      0.16      0.17       304\n",
      "           7       0.29      0.39      0.33       129\n",
      "\n",
      "    accuracy                           0.24      2000\n",
      "   macro avg       0.24      0.26      0.24      2000\n",
      "weighted avg       0.24      0.24      0.23      2000\n",
      "\n",
      "min leaves=10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.25      0.28       297\n",
      "           1       0.33      0.29      0.31       401\n",
      "           2       0.20      0.36      0.26       146\n",
      "           3       0.23      0.18      0.20       277\n",
      "           4       0.17      0.36      0.23       134\n",
      "           5       0.32      0.19      0.24       312\n",
      "           6       0.17      0.14      0.15       304\n",
      "           7       0.34      0.50      0.41       129\n",
      "\n",
      "    accuracy                           0.26      2000\n",
      "   macro avg       0.26      0.28      0.26      2000\n",
      "weighted avg       0.27      0.26      0.25      2000\n",
      "\n",
      "min leaves=25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.31      0.32       297\n",
      "           1       0.29      0.21      0.25       401\n",
      "           2       0.21      0.41      0.28       146\n",
      "           3       0.27      0.20      0.23       277\n",
      "           4       0.16      0.40      0.23       134\n",
      "           5       0.32      0.18      0.23       312\n",
      "           6       0.16      0.14      0.15       304\n",
      "           7       0.32      0.43      0.36       129\n",
      "\n",
      "    accuracy                           0.25      2000\n",
      "   macro avg       0.26      0.28      0.26      2000\n",
      "weighted avg       0.27      0.25      0.25      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "leaf_ls=[1,3,5,7,10,25]\n",
    "for leaf_num in leaf_ls:\n",
    "    print(\"min leaves=\"+str(leaf_num))\n",
    "    model=tree.DecisionTreeClassifier(min_samples_leaf=leaf_num)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test) # Predicting labels for our test set using trained\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def LR_exp(c):\n",
    "    print(\"Regularization parameter(C)=\"+str(c))\n",
    "    model = LogisticRegression(C=c,  multi_class='multinomial', solver='lbfgs')\n",
    "    model.fit(X_train, y_train) # Training the model\n",
    "    y_pred = model.predict(X_test) # Predicting labels for our test set using trained\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization parameter(C)=0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.23      0.28       297\n",
      "           1       0.29      0.06      0.10       401\n",
      "           2       0.23      0.43      0.30       146\n",
      "           3       0.29      0.20      0.24       277\n",
      "           4       0.19      0.72      0.30       134\n",
      "           5       0.32      0.13      0.19       312\n",
      "           6       0.19      0.24      0.21       304\n",
      "           7       0.36      0.71      0.48       129\n",
      "\n",
      "    accuracy                           0.26      2000\n",
      "   macro avg       0.28      0.34      0.26      2000\n",
      "weighted avg       0.29      0.26      0.23      2000\n",
      "\n",
      "Regularization parameter(C)=0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.29      0.33       297\n",
      "           1       0.28      0.13      0.18       401\n",
      "           2       0.30      0.45      0.36       146\n",
      "           3       0.32      0.38      0.35       277\n",
      "           4       0.18      0.56      0.28       134\n",
      "           5       0.48      0.25      0.33       312\n",
      "           6       0.24      0.20      0.22       304\n",
      "           7       0.41      0.71      0.52       129\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.33      0.37      0.32      2000\n",
      "weighted avg       0.33      0.31      0.29      2000\n",
      "\n",
      "Regularization parameter(C)=0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.34      0.37       297\n",
      "           1       0.32      0.17      0.22       401\n",
      "           2       0.37      0.47      0.41       146\n",
      "           3       0.38      0.42      0.40       277\n",
      "           4       0.23      0.60      0.33       134\n",
      "           5       0.55      0.40      0.47       312\n",
      "           6       0.22      0.20      0.21       304\n",
      "           7       0.43      0.64      0.51       129\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.36      0.40      0.37      2000\n",
      "weighted avg       0.37      0.35      0.35      2000\n",
      "\n",
      "Regularization parameter(C)=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.33      0.37       297\n",
      "           1       0.33      0.21      0.26       401\n",
      "           2       0.33      0.43      0.38       146\n",
      "           3       0.39      0.42      0.41       277\n",
      "           4       0.22      0.61      0.32       134\n",
      "           5       0.49      0.34      0.40       312\n",
      "           6       0.23      0.18      0.20       304\n",
      "           7       0.37      0.53      0.44       129\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.35      0.38      0.35      2000\n",
      "weighted avg       0.36      0.34      0.33      2000\n",
      "\n",
      "Regularization parameter(C)=10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.35      0.39       297\n",
      "           1       0.34      0.20      0.26       401\n",
      "           2       0.34      0.43      0.38       146\n",
      "           3       0.38      0.43      0.40       277\n",
      "           4       0.22      0.60      0.32       134\n",
      "           5       0.55      0.33      0.41       312\n",
      "           6       0.21      0.20      0.20       304\n",
      "           7       0.38      0.56      0.45       129\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.36      0.39      0.35      2000\n",
      "weighted avg       0.37      0.34      0.34      2000\n",
      "\n",
      "Regularization parameter(C)=100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.37      0.40       297\n",
      "           1       0.33      0.17      0.23       401\n",
      "           2       0.36      0.47      0.40       146\n",
      "           3       0.40      0.44      0.42       277\n",
      "           4       0.21      0.61      0.32       134\n",
      "           5       0.55      0.31      0.40       312\n",
      "           6       0.19      0.20      0.20       304\n",
      "           7       0.36      0.47      0.41       129\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.35      0.38      0.35      2000\n",
      "weighted avg       0.36      0.33      0.33      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "for c in C_param_range:\n",
    "    LR_exp(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def SVM_exp(c):\n",
    "    print(\"Regularization parameter(C)=\"+str(c))\n",
    "    model = SVC(C=c, gamma='auto', kernel='rbf')\n",
    "    model.fit(X_train, y_train)# Training SVM\n",
    "    y_pred = model.predict(X_test) # Predicting labels for our test set using trained\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization parameter(C)=0.001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       328\n",
      "           1       0.00      0.00      0.00       380\n",
      "           2       0.00      0.00      0.00       431\n",
      "           3       0.00      0.00      0.00       316\n",
      "           4       0.15      1.00      0.26       456\n",
      "           5       0.00      0.00      0.00       340\n",
      "           6       0.00      0.00      0.00       426\n",
      "           7       0.00      0.00      0.00       323\n",
      "\n",
      "    accuracy                           0.15      3000\n",
      "   macro avg       0.02      0.12      0.03      3000\n",
      "weighted avg       0.02      0.15      0.04      3000\n",
      "\n",
      "Regularization parameter(C)=0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       328\n",
      "           1       0.00      0.00      0.00       380\n",
      "           2       0.00      0.00      0.00       431\n",
      "           3       0.00      0.00      0.00       316\n",
      "           4       0.15      1.00      0.26       456\n",
      "           5       0.00      0.00      0.00       340\n",
      "           6       0.00      0.00      0.00       426\n",
      "           7       0.00      0.00      0.00       323\n",
      "\n",
      "    accuracy                           0.15      3000\n",
      "   macro avg       0.02      0.12      0.03      3000\n",
      "weighted avg       0.02      0.15      0.04      3000\n",
      "\n",
      "Regularization parameter(C)=0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       328\n",
      "           1       0.00      0.00      0.00       380\n",
      "           2       0.21      0.01      0.02       431\n",
      "           3       0.00      0.00      0.00       316\n",
      "           4       0.29      0.57      0.38       456\n",
      "           5       0.00      0.00      0.00       340\n",
      "           6       0.17      0.81      0.28       426\n",
      "           7       0.00      0.00      0.00       323\n",
      "\n",
      "    accuracy                           0.20      3000\n",
      "   macro avg       0.08      0.17      0.09      3000\n",
      "weighted avg       0.10      0.20      0.10      3000\n",
      "\n",
      "Regularization parameter(C)=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.09      0.16       328\n",
      "           1       0.71      0.04      0.08       380\n",
      "           2       0.54      0.46      0.50       431\n",
      "           3       0.36      0.21      0.26       316\n",
      "           4       0.41      0.57      0.47       456\n",
      "           5       0.72      0.22      0.34       340\n",
      "           6       0.21      0.57      0.31       426\n",
      "           7       0.35      0.51      0.42       323\n",
      "\n",
      "    accuracy                           0.35      3000\n",
      "   macro avg       0.47      0.33      0.32      3000\n",
      "weighted avg       0.46      0.35      0.33      3000\n",
      "\n",
      "Regularization parameter(C)=10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.44      0.44       328\n",
      "           1       0.56      0.24      0.33       380\n",
      "           2       0.60      0.55      0.57       431\n",
      "           3       0.51      0.61      0.56       316\n",
      "           4       0.47      0.55      0.51       456\n",
      "           5       0.59      0.37      0.46       340\n",
      "           6       0.32      0.49      0.39       426\n",
      "           7       0.50      0.54      0.52       323\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.50      0.47      0.47      3000\n",
      "weighted avg       0.50      0.48      0.47      3000\n",
      "\n",
      "Regularization parameter(C)=100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.60      0.56       328\n",
      "           1       0.54      0.44      0.48       380\n",
      "           2       0.67      0.67      0.67       431\n",
      "           3       0.63      0.66      0.65       316\n",
      "           4       0.61      0.65      0.63       456\n",
      "           5       0.72      0.58      0.64       340\n",
      "           6       0.48      0.52      0.50       426\n",
      "           7       0.61      0.62      0.62       323\n",
      "\n",
      "    accuracy                           0.59      3000\n",
      "   macro avg       0.60      0.59      0.59      3000\n",
      "weighted avg       0.60      0.59      0.59      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "for c in C_param_range:\n",
    "    SVM_exp(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization parameter(C)=150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42       297\n",
      "           1       0.32      0.22      0.26       401\n",
      "           2       0.40      0.48      0.44       146\n",
      "           3       0.44      0.41      0.43       277\n",
      "           4       0.24      0.60      0.34       134\n",
      "           5       0.53      0.27      0.36       312\n",
      "           6       0.20      0.20      0.20       304\n",
      "           7       0.44      0.65      0.53       129\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.37      0.41      0.37      2000\n",
      "weighted avg       0.37      0.35      0.35      2000\n",
      "\n",
      "Regularization parameter(C)=200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.41      0.41       297\n",
      "           1       0.31      0.23      0.26       401\n",
      "           2       0.40      0.48      0.44       146\n",
      "           3       0.45      0.41      0.43       277\n",
      "           4       0.24      0.60      0.34       134\n",
      "           5       0.51      0.26      0.35       312\n",
      "           6       0.20      0.19      0.20       304\n",
      "           7       0.44      0.67      0.53       129\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.37      0.41      0.37      2000\n",
      "weighted avg       0.37      0.35      0.35      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_param_range = [150,200]\n",
    "for c in C_param_range:\n",
    "    SVM_exp(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def KNN_exp(n):\n",
    "    print(\"n_neighbors=\"+str(n))\n",
    "    model = KNeighborsClassifier(n_neighbors=n) #\n",
    "    model.fit(X_train, y_train) # Training the model\n",
    "    # Evaluate the model:\n",
    "    y_pred = model.predict(X_test) # Predicting labels for our test set using trained\n",
    "    print(classification_report(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors=5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.26      0.29       297\n",
      "           1       0.28      0.25      0.26       401\n",
      "           2       0.36      0.45      0.40       146\n",
      "           3       0.25      0.30      0.27       277\n",
      "           4       0.20      0.31      0.24       134\n",
      "           5       0.46      0.40      0.43       312\n",
      "           6       0.24      0.16      0.19       304\n",
      "           7       0.47      0.62      0.53       129\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.32      0.35      0.33      2000\n",
      "weighted avg       0.31      0.31      0.31      2000\n",
      "\n",
      "n_neighbors=10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.30      0.32       297\n",
      "           1       0.26      0.21      0.24       401\n",
      "           2       0.39      0.47      0.43       146\n",
      "           3       0.28      0.38      0.32       277\n",
      "           4       0.19      0.32      0.24       134\n",
      "           5       0.47      0.44      0.45       312\n",
      "           6       0.22      0.14      0.17       304\n",
      "           7       0.49      0.66      0.56       129\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.33      0.36      0.34      2000\n",
      "weighted avg       0.32      0.33      0.32      2000\n",
      "\n",
      "n_neighbors=20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.30      0.33       297\n",
      "           1       0.27      0.18      0.22       401\n",
      "           2       0.40      0.48      0.44       146\n",
      "           3       0.30      0.42      0.35       277\n",
      "           4       0.19      0.35      0.24       134\n",
      "           5       0.51      0.43      0.47       312\n",
      "           6       0.23      0.15      0.18       304\n",
      "           7       0.42      0.65      0.51       129\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.33      0.37      0.34      2000\n",
      "weighted avg       0.33      0.33      0.32      2000\n",
      "\n",
      "n_neighbors=40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.26      0.32       297\n",
      "           1       0.25      0.13      0.18       401\n",
      "           2       0.39      0.49      0.43       146\n",
      "           3       0.31      0.49      0.38       277\n",
      "           4       0.22      0.46      0.30       134\n",
      "           5       0.51      0.46      0.48       312\n",
      "           6       0.23      0.15      0.18       304\n",
      "           7       0.40      0.64      0.49       129\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.34      0.39      0.35      2000\n",
      "weighted avg       0.34      0.34      0.32      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in [5,10,20,40]:\n",
    "    KNN_exp(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.05      0.09       297\n",
      "           1       0.36      0.04      0.07       401\n",
      "           2       0.15      0.45      0.23       146\n",
      "           3       0.31      0.50      0.39       277\n",
      "           4       0.28      0.67      0.39       134\n",
      "           5       0.31      0.06      0.10       312\n",
      "           6       0.19      0.10      0.13       304\n",
      "           7       0.24      0.91      0.38       129\n",
      "\n",
      "    accuracy                           0.24      2000\n",
      "   macro avg       0.26      0.35      0.22      2000\n",
      "weighted avg       0.27      0.24      0.18      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train) # Training the model\n",
    "y_pred = model.predict(X_test) # Predicting labels for our test set using trained\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM\n",
    "#### w/o kmeans mean init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "model=GaussianMixture(n_components=8,)\n",
    "model.fit(X_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       297\n",
      "           1       0.25      0.02      0.04       401\n",
      "           2       0.00      0.00      0.00       146\n",
      "           3       0.00      0.00      0.00       277\n",
      "           4       0.00      0.00      0.00       134\n",
      "           5       0.00      0.00      0.00       312\n",
      "           6       0.15      0.99      0.27       304\n",
      "           7       0.00      0.00      0.00       129\n",
      "\n",
      "    accuracy                           0.15      2000\n",
      "   macro avg       0.05      0.13      0.04      2000\n",
      "weighted avg       0.07      0.15      0.05      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bad because unsupervised learning, y_train not used,but can try init mean based on its genre (1 song from each genre)\n",
    "#### w kmeans init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26       297\n",
      "           1       0.00      0.00      0.00       401\n",
      "           2       0.00      0.00      0.00       146\n",
      "           3       0.00      0.00      0.00       277\n",
      "           4       0.00      0.00      0.00       134\n",
      "           5       0.00      0.00      0.00       312\n",
      "           6       0.00      0.00      0.00       304\n",
      "           7       0.00      0.00      0.00       129\n",
      "\n",
      "    accuracy                           0.15      2000\n",
      "   macro avg       0.02      0.12      0.03      2000\n",
      "weighted avg       0.02      0.15      0.04      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "means=np.load('X_example.npy')\n",
    "from sklearn.mixture import GaussianMixture\n",
    "model=GaussianMixture(n_components=8,init_params='kmeans',means_init=means)\n",
    "model.fit(X_train)\n",
    "y_pred=model.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98565\n",
      "98567\n",
      "98569\n"
     ]
    }
   ],
   "source": [
    "#####data processing######\n",
    "import numpy as np\n",
    "X=[]\n",
    "Y=[]\n",
    "####normalize\n",
    "_min,_max=float('inf'),-float('inf')\n",
    "for fpath in glob.glob('/home/pengfei/yunyi/beatbrain/data/fma/numpy/*/*'):\n",
    "    #based on track_id get test/val/train\n",
    "    track_id=int(fpath[-10:-4])\n",
    "    ########use fma predefined split####\n",
    "    #split=tracks.loc[track_id][\"set\"][\"split\"]\n",
    "    genre=tracks.loc[track_id][\"track\"][\"genre_top\"]\n",
    "    #load data\n",
    "    nps=utils.load_arrays(fpath)\n",
    "    for npz in nps:\n",
    "        if npz.shape!=(512, 640):\n",
    "            print(track_id)\n",
    "        else:\n",
    "            X.append(npz)\n",
    "            Y.append(genre)\n",
    "            ###########normalize code(unused)\n",
    "            _min=min(np.amin(npz),_min)\n",
    "            _max=max(np.amax(npz),_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### above is track_id whose mel spec with wrong duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(512, 640)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([X[i].shape for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####normalize(unused)\n",
    "X=(X-_min)/(_max-_min)\n",
    "#change y to categorical int\n",
    "lookupTable, Y = np.unique(Y, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_dl.npy',X) # save\n",
    "np.save('Y_dl.npy',Y)\n",
    "np.save('min_dl.npy',_min) # save\n",
    "np.save('max_dl.npy',_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX=np.load('X_dl.npy') # save\\nY=np.load('Y_dl.npy')\\n_min=np.load('min.npy') # save\\n_max=np.load('max.npy')\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X=np.load('X_dl.npy') # save\n",
    "Y=np.load('Y_dl.npy')\n",
    "_min=np.load('min.npy') # save\n",
    "_max=np.load('max.npy')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43320, 512, 640), (43320,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL-GPU device setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "os.environ['VISIBLE_CUDA_DEVICES'] = \"0\"\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dropout, Dense, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained DL-X,DL-Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=np.load('X_dl.npy') # save\n",
    "Y=np.load('Y_dl.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_model(input_shape):\n",
    "    #shape of RNN (n,time,feat)\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(128,return_sequences=True,input_shape=input_shape))\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(64,activation=\"relu\")))\n",
    "    model.add(TimeDistributed(Dense(32,activation=\"relu\")))\n",
    "    model.add(TimeDistributed(Dense(16,activation=\"relu\")))\n",
    "    model.add(TimeDistributed(Dense(8,activation=\"relu\")))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8,activation=\"softmax\"))\n",
    "    #model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# for rec ############################\n",
    "X=X.reshape(X.shape[0],X.shape[1],X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43320, 512, 640)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_b = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43320, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 8320 samples\n",
      "Epoch 1/10\n",
      "35000/35000 [==============================] - 93s 3ms/sample - loss: 1.8005 - acc: 0.3246 - val_loss: 1.6934 - val_acc: 0.3681\n",
      "Epoch 2/10\n",
      "35000/35000 [==============================] - 88s 3ms/sample - loss: 1.5572 - acc: 0.4416 - val_loss: 1.6978 - val_acc: 0.3927\n",
      "Epoch 3/10\n",
      "35000/35000 [==============================] - 87s 2ms/sample - loss: 1.4558 - acc: 0.4846 - val_loss: 1.6649 - val_acc: 0.4028\n",
      "Epoch 4/10\n",
      "35000/35000 [==============================] - 86s 2ms/sample - loss: 1.3524 - acc: 0.5230 - val_loss: 1.7608 - val_acc: 0.4106\n",
      "Epoch 5/10\n",
      "35000/35000 [==============================] - 86s 2ms/sample - loss: 1.2674 - acc: 0.5567 - val_loss: 1.8357 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "35000/35000 [==============================] - 85s 2ms/sample - loss: 1.2008 - acc: 0.5788 - val_loss: 1.8131 - val_acc: 0.4038\n",
      "Epoch 7/10\n",
      "35000/35000 [==============================] - 85s 2ms/sample - loss: 1.1231 - acc: 0.6064 - val_loss: 1.9263 - val_acc: 0.3950\n",
      "Epoch 8/10\n",
      "35000/35000 [==============================] - 85s 2ms/sample - loss: 1.0606 - acc: 0.6278 - val_loss: 2.0128 - val_acc: 0.3679\n",
      "Epoch 9/10\n",
      "35000/35000 [==============================] - 85s 2ms/sample - loss: 1.0021 - acc: 0.6501 - val_loss: 2.0071 - val_acc: 0.3791\n",
      "Epoch 10/10\n",
      "35000/35000 [==============================] - 85s 2ms/sample - loss: 0.9493 - acc: 0.6689 - val_loss: 2.1678 - val_acc: 0.3668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43680d3ad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(X.shape[1],X.shape[2])\n",
    "model=get_recurrent_model(input_shape)\n",
    "#checkpoint=ModelCheckpoint(\"rnn.model\",monitor=\"val_acc\",verbose=1,mode=\"max\",\n",
    "#                           save_best_only=True,save_weights_only=False,periods=1)\n",
    "model.fit(X[:35000],Y_b[:35000],epochs=10,batch_size=32,shuffle=True,\n",
    "          validation_data=(X[35000:],Y_b[35000:])\n",
    "         # ,callbacks=[checkpoint]\n",
    "         )\n",
    "#model.save(\"rnn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 512, 128)          393728    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 512, 64)           8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 512, 32)           2080      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 512, 16)           528       \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 512, 8)            136       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 32776     \n",
      "=================================================================\n",
      "Total params: 569,088\n",
      "Trainable params: 569,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"rnn.model\")\n",
    "model=get_recurrent_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(input_shape):\n",
    "    model=Sequential()\n",
    "    #model.add(Conv2D(16,(3,3),activation=\"relu\",strides=(1,1),padding=\"same\"))\n",
    "    model.add(Conv2D(16,(3,3),activation=\"relu\",strides=(1,1),padding=\"same\"))\n",
    "    model.add(Conv2D(16,(3,3),activation=\"relu\",strides=(1,1),padding=\"same\"))\n",
    "    model.add(Conv2D(16,(3,3),activation=\"relu\",strides=(1,1),padding=\"same\"))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(64,activation=\"relu\"))\n",
    "    model.add(Dense(8,activation=\"softmax\"))\n",
    "    #model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 8320 samples\n",
      "Epoch 1/10\n",
      "34976/35000 [============================>.] - ETA: 0s - loss: 1.6887 - acc: 0.4035\n",
      "Epoch 00001: val_acc improved from -inf to 0.41791, saving model to conv.model\n",
      "WARNING:tensorflow:From /home/pengfei/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: conv.model/assets\n",
      "35000/35000 [==============================] - 457s 13ms/sample - loss: 1.6884 - acc: 0.4036 - val_loss: 1.6417 - val_acc: 0.4179\n",
      "Epoch 2/10\n",
      "34976/35000 [============================>.] - ETA: 0s - loss: 1.1284 - acc: 0.6098\n",
      "Epoch 00002: val_acc did not improve from 0.41791\n",
      "35000/35000 [==============================] - 432s 12ms/sample - loss: 1.1284 - acc: 0.6099 - val_loss: 1.8798 - val_acc: 0.3851\n",
      "Epoch 3/10\n",
      "26720/35000 [=====================>........] - ETA: 1:36 - loss: 0.4908 - acc: 0.8360WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-659f7b14585c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                            save_best_only=True,save_weights_only=False,periods=1)\n\u001b[1;32m     10\u001b[0m model.fit(X[:35000],Y_b[:35000],epochs=10,batch_size=32,shuffle=True,\n\u001b[0;32m---> 11\u001b[0;31m           validation_data=(X[35000:],Y_b[35000:]),callbacks=[checkpoint])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conv.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############for conv ##########################\n",
    "X=X.reshape(X.shape[0],X.shape[1],X.shape[2],1)\n",
    "input_shape=(X.shape[1],X.shape[2],1)\n",
    "\n",
    "model=get_conv_model(input_shape)\n",
    "###train and evel\n",
    "#class_weight=compute_class_weight(\"balanced\",np.unique(y),y_flat)\n",
    "checkpoint=ModelCheckpoint(\"conv.model\",monitor=\"val_acc\",verbose=1,mode=\"max\",\n",
    "                           save_best_only=True,save_weights_only=False,periods=1)\n",
    "model.fit(X[:35000],Y_b[:35000],epochs=10,batch_size=32,shuffle=True,\n",
    "          validation_data=(X[35000:],Y_b[35000:]),callbacks=[checkpoint])\n",
    "model.save(\"conv.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-87d71f6fe6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conv_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \"\"\"\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1258\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model=get_conv_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
