{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import wave\n",
    "import librosa\n",
    "import resampy\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from natsort import natsorted\n",
    "from loguru import logger\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_segments(path, max_segment_length, min_segment_length):\n",
    "    try:\n",
    "        with wave.open(str(path), mode=\"r\") as wavefile:\n",
    "            sr = wavefile.getframerate()\n",
    "            samples = wavefile.getnframes()\n",
    "            duration = samples / sr\n",
    "            num_segments = int(duration / max_segment_length)\n",
    "            if duration % max_segment_length >= min_segment_length:\n",
    "                num_segments += 1\n",
    "            return num_segments\n",
    "    except wave.Error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class WavDataset(Dataset):\n",
    "    def __init__(self, paths, max_segment_length=10, min_segment_length=4, sample_rate=22050, mono=True):\n",
    "        super().__init__()\n",
    "        # Scan for wav file(s)\n",
    "        if isinstance(paths, (str, Path)):\n",
    "            # Single file or single directory\n",
    "            paths = Path(paths)\n",
    "            self.paths = list(paths.iterdir()) if paths.is_dir() else [paths]\n",
    "        else:\n",
    "            # List of files\n",
    "            self.paths = list(map(Path, paths))\n",
    "        if any([path.suffix.lower() != \".wav\" for path in self.paths]):\n",
    "            logger.warning(\"One or more filenames have a file extension other than '.wav'\")\n",
    "        self.paths = np.asarray(natsorted(self.paths))\n",
    "\n",
    "        self.max_segment_length = max_segment_length\n",
    "        self.min_segment_length = min_segment_length\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mono = mono\n",
    "\n",
    "        self.num_track_segments = np.array(Parallel(n_jobs=-1)(delayed(get_num_segments)(str(path), self.max_segment_length, self.min_segment_length) for path in self.paths))\n",
    "        valid_tracks_mask = self.num_track_segments > 0\n",
    "        invalid_tracks_mask = ~valid_tracks_mask\n",
    "        if invalid_tracks_mask.sum() > 0:\n",
    "            logger.warning(f\"Failed to load {invalid_tracks_mask.sum()} tracks.\")\n",
    "            for invalid_index in invalid_tracks_mask.nonzero()[0]:\n",
    "                logger.debug(f\"Failed to load {str(self.paths[invalid_index])}\")\n",
    "            self.paths = self.paths[valid_tracks_mask]\n",
    "            self.num_track_segments = self.num_track_segments[valid_tracks_mask]\n",
    "        self.cumulative_num_track_segments = np.cumsum(self.num_track_segments)\n",
    "        self.num_total_segments = self.cumulative_num_track_segments[-1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < 0:\n",
    "            index = self.num_total_segments + index\n",
    "        if index >= len(self):\n",
    "            raise IndexError(f\"Sample index out of range. Max index is {len(self) - 1}\")\n",
    "        track_index = np.min(np.where(self.cumulative_num_track_segments > index))\n",
    "        if track_index == 0:\n",
    "            index_remainder = index\n",
    "        else:\n",
    "            index_remainder = index - self.cumulative_num_track_segments[track_index - 1]\n",
    "        track_path = self.paths[track_index]\n",
    "        with wave.open(str(track_path), mode=\"r\") as wavefile:\n",
    "            num_channels, sample_width, track_sample_rate, track_num_samples, _, _ = wavefile.getparams()\n",
    "            start_pos = track_sample_rate * self.max_segment_length * index_remainder\n",
    "            num_samples = track_sample_rate * self.max_segment_length\n",
    "\n",
    "            # Load raw audio\n",
    "            wavefile.setpos(start_pos)\n",
    "            buffer = wavefile.readframes(num_samples)\n",
    "            if sample_width == 3:\n",
    "                audio = np.empty((num_samples, num_channels, 4), dtype=np.uint8)\n",
    "                raw_bytes = np.frombuffer(buffer, dtype=np.uint8)\n",
    "                audio[:, :, :sample_width] = raw_bytes.reshape(-1, num_channels, sample_width)\n",
    "                audio[:, :, sample_width:] = (a[:, :, sample_width - 1:sample_width] >> 7) * 255\n",
    "                audio = audio.view('<i4').reshape(audio.shape[:-1])\n",
    "            else:\n",
    "                audio = np.frombuffer(buffer, dtype=f\"<{'u' if sample_width == 1 else 'i'}{sample_width}\").reshape(-1, num_channels)\n",
    "            audio = audio.T  # Channel-first index order\n",
    "\n",
    "            # Convert to tensor\n",
    "            audio = librosa.util.fix_length(audio, num_samples)\n",
    "            if self.sample_rate is None or self.sample_rate == track_sample_rate:\n",
    "                output_sr = track_sample_rate\n",
    "            else:\n",
    "                audio = resampy.resample(audio, track_sample_rate, self.sample_rate, filter=\"kaiser_fast\")\n",
    "                output_sr = self.sample_rate\n",
    "            if self.mono and audio.ndim > 1:\n",
    "                audio = audio.mean(0)\n",
    "            return torch.tensor(audio, dtype=torch.float32), torch.tensor(output_sr, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cumulative_num_track_segments[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUDIO_DIR = Path(\"../data/shetti/original/[WAV] Eurobeat Remix Stand Proud.wav\")\n",
    "WAV_DIR = Path(\"../data/shetti/wavs-22050/\")\n",
    "MAX_SEGMENT_LENGTH = 5\n",
    "MIN_SEGMENT_LENGTH = 1\n",
    "SAMPLE_RATE = 22050\n",
    "MONO = True\n",
    "\n",
    "dataset = WavDataset(WAV_DIR, max_segment_length=MAX_SEGMENT_LENGTH, min_segment_length=MIN_SEGMENT_LENGTH, sample_rate=SAMPLE_RATE, mono=MONO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5011af57372f483a9695ece4f577afed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1079.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total iteration time: 47.88576793670654\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=6)\n",
    "start = time()\n",
    "for audio, sr in tqdm(dataloader):\n",
    "    pass\n",
    "#     audio.cuda(), sr.cuda()\n",
    "print(\"Total iteration time:\", time() - start)\n",
    "# audio, sr = dataset[14]\n",
    "# display(Audio(audio, rate=sr, autoplay=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
