{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# scientific\n",
    "import numpy as np\n",
    "import beatbrain\n",
    "from beatbrain import utils\n",
    "\n",
    "# visualization\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Lambda, Reshape\n",
    "from tensorflow.keras.callbacks import (\n",
    "    Callback,\n",
    "    TensorBoard,\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TerminateOnNaN,\n",
    "    CSVLogger,\n",
    "    LambdaCallback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "DATA_ROOT = Path(\"../data/fma/image\")\n",
    "IMAGE_DIMS = [512, 640, 1]\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"train\", batch_size=BATCH_SIZE, parallel=False\n",
    ")\n",
    "val_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"val\", batch_size=BATCH_SIZE, parallel=False,\n",
    ")\n",
    "test_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"test\", batch_size=1, parallel=False, shuffle_buffer=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cvae(latent_dim, input_shape, num_conv=3, batch_size=1, learning_rate=1e-3):\n",
    "    def reparam(args):\n",
    "        z_mean, z_log_var = args\n",
    "        dim = tf.keras.backend.int_shape(z_mean)[1]\n",
    "        eps = tf.keras.backend.random_normal(shape=(batch_size, dim))\n",
    "        return eps * tf.exp(z_log_var * 0.5) + z_mean\n",
    "\n",
    "    encoder_input = tf.keras.Input(shape=input_shape, batch_size=batch_size)\n",
    "    e = tf.keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
    "    )(encoder_input)\n",
    "    for i in range(num_conv):\n",
    "        e = tf.keras.layers.Conv2D(\n",
    "            filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
    "        )(e)\n",
    "    decoder_input_shape = tf.keras.backend.int_shape(e)\n",
    "    # decoder_input_shape: (1, 31, 39, 64)\n",
    "    e = tf.keras.layers.Flatten()(e)\n",
    "    e = tf.keras.layers.Dense(16)(e)\n",
    "    z_mean = tf.keras.layers.Dense(latent_dim)(e)\n",
    "    z_log_var = tf.keras.layers.Dense(latent_dim)(e)\n",
    "    z = tf.keras.layers.Lambda(reparam, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    decoder_input_shape = (\n",
    "        1,\n",
    "        input_shape[0] // (2 ** (num_conv + 1)),\n",
    "        input_shape[1] // (2 ** (num_conv + 1)),\n",
    "        64,\n",
    "    )\n",
    "    # (decoder_input_shape): (32, 40, 64)\n",
    "\n",
    "    decoder_input = tf.keras.Input(shape=(latent_dim,))\n",
    "    d = tf.keras.layers.Dense(\n",
    "        decoder_input_shape[1] * decoder_input_shape[2] * decoder_input_shape[3],\n",
    "        activation=tf.nn.relu,\n",
    "    )(decoder_input)\n",
    "    d = tf.keras.layers.Reshape(\n",
    "        target_shape=(\n",
    "            decoder_input_shape[1],\n",
    "            decoder_input_shape[2],\n",
    "            decoder_input_shape[3],\n",
    "        )\n",
    "    )(d)\n",
    "    # d.shape: (None, 31, 39, 64)\n",
    "    for i in range(num_conv):\n",
    "        d = tf.keras.layers.Conv2DTranspose(\n",
    "            filters=64,\n",
    "            kernel_size=3,\n",
    "            strides=(2, 2),\n",
    "            padding=\"SAME\",\n",
    "            activation=\"relu\",\n",
    "        )(d)\n",
    "    d = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\",\n",
    "    )(d)\n",
    "    decoder_output = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\",\n",
    "    )(d)\n",
    "\n",
    "    decoder = tf.keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "    outputs = decoder(encoder(encoder_input)[2])\n",
    "    model = tf.keras.Model(encoder_input, outputs, name=\"vae\")\n",
    "\n",
    "    assert encoder_input.shape == outputs.shape\n",
    "    reconstruction_loss = tf.losses.mse(encoder_input, outputs)\n",
    "    reconstruction_loss = tf.reduce_sum(reconstruction_loss, axis=[1, 2])\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "    logpz = log_normal_pdf(z, 0.0, 0.0)\n",
    "    logqz_x = log_normal_pdf(z, z_mean, z_log_var)\n",
    "    kl_loss = logqz_x - logpz\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    model.add_loss(vae_loss)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "    return model, encoder, decoder\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + log2pi), axis=raxis\n",
    "    )\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample(latent_dim, decoder, eps=None):\n",
    "    if eps is None:\n",
    "        eps = tf.random.normal(shape=(100, latent_dim))\n",
    "    return decode(decoder, eps, apply_sigmoid=True)\n",
    "\n",
    "\n",
    "def encode(encoder, x):\n",
    "    inference = encoder(x)\n",
    "    mean, logvar = tf.split(inference, num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "\n",
    "def reparameterize(mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "\n",
    "def decode(decoder, z, apply_sigmoid=False):\n",
    "    logits = decoder(z)\n",
    "    if apply_sigmoid:\n",
    "        probs = tf.sigmoid(logits)\n",
    "        return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Model Output, and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LATENT_DIM = 256\n",
    "EPOCHS = 50\n",
    "NUM_CONV = 3\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Callback options\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "REDUCE_LR_PATIENCE = 1\n",
    "\n",
    "# Outputs\n",
    "MODEL_NAME = \"2d-CVAE\"\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "LOG_DIR = Path(\"../logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizeCallback(Callback):\n",
    "    def __init__(\n",
    "        self, log_dir, latent_dim, validation_data, n_examples=4, random_vectors=None,\n",
    "    ):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_examples = n_examples\n",
    "\n",
    "        self.random_vectors = random_vectors or tf.random.normal(\n",
    "            shape=[n_examples, latent_dim]\n",
    "        )\n",
    "        self.data = list(validation_data.unbatch().take(self.n_examples))\n",
    "\n",
    "        self.recon_raw = self.log_dir / \"raw\" / \"reconstructed\"\n",
    "        self.recon_png = self.log_dir / \"png\" / \"reconstructed\"\n",
    "        self.gen_raw = self.log_dir / \"raw\" / \"generated\"\n",
    "        self.gen_png = self.log_dir / \"png\" / \"generated\"\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.recon_raw.mkdir(exist_ok=True, parents=True)\n",
    "        self.recon_png.mkdir(exist_ok=True, parents=True)\n",
    "        self.gen_raw.mkdir(exist_ok=True, parents=True)\n",
    "        self.gen_png.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def _visualize_reconstruction(self, epoch):\n",
    "        #         data = self.validation_data.unbatch().take(self.n_examples)\n",
    "        for i, sample in enumerate(self.data):\n",
    "            sample = sample[None, :]\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "            #             plt.subplots_adjust(\n",
    "            #                 left=None, bottom=None, right=None, top=None, wspace=None, hspace=None\n",
    "            #             )\n",
    "            plt.sca(axes[0])\n",
    "            beatbrain.display.show_spec(\n",
    "                utils.denormalize_spectrogram(sample[0, ..., 0].numpy()),\n",
    "                title=\"Original\",\n",
    "            )\n",
    "            plt.sca(axes[1])\n",
    "            reconstructed = self.model(sample)\n",
    "            beatbrain.display.show_spec(\n",
    "                utils.denormalize_spectrogram(reconstructed[0, ..., 0].numpy()),\n",
    "                title=\"Reconstructed\",\n",
    "            )\n",
    "            fig.tight_layout()\n",
    "            title = f\"recon_{i + 1}@epoch_{epoch}\"\n",
    "            fig.suptitle(title)\n",
    "            plt.savefig(self.recon_png / f\"{title}.png\")\n",
    "            utils.save_image(\n",
    "                reconstructed[0, ..., 0], self.recon_raw / f\"{title}.exr\",\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "    def _visualize_generation(self, epoch):\n",
    "        decoder = self.model.get_layer(\"decoder\")\n",
    "        generated = decoder(self.random_vectors)\n",
    "        for i, gen in enumerate(generated):\n",
    "            gen = gen[None, :]\n",
    "            fig = plt.figure()\n",
    "            title = f\"gen_{i + 1}@epoch_{epoch}\"\n",
    "            beatbrain.display.show_spec(\n",
    "                utils.denormalize_spectrogram(gen[0, ..., 0].numpy()), title=title,\n",
    "            )\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(self.gen_png / f\"{title}.png\")\n",
    "            utils.save_image(gen[0, ..., 0], self.gen_raw / f\"{title}.exr\")\n",
    "            plt.close()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self._visualize_reconstruction(epoch)\n",
    "        self._visualize_generation(epoch)\n",
    "        # if epoch >= 2:\n",
    "        #     raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(\n",
    "    log_dir=LOG_DIR / MODEL_NAME, update_freq=256, profile_batch=0,\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(patience=1, factor=0.1, min_lr=1e-5, verbose=1,)\n",
    "early_stop = EarlyStopping(patience=3, verbose=1,)\n",
    "model_saver = ModelCheckpoint(\n",
    "    str(MODEL_DIR / MODEL_NAME), save_best_only=True, verbose=1,\n",
    ")\n",
    "csv_logger = CSVLogger(f\"{LOG_DIR / MODEL_NAME / 'log'}.csv\")\n",
    "visualizer = VisualizeCallback(LOG_DIR / MODEL_NAME, LATENT_DIM, val_dataset,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, encoder, decoder = build_cvae(\n",
    "    LATENT_DIM,\n",
    "    IMAGE_DIMS,\n",
    "    num_conv=NUM_CONV,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit_generator(\n",
    "    train_dataset.take(5),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tensorboard, reduce_lr, early_stop, model_saver, visualizer,],\n",
    "    validation_data=val_dataset.take(5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - reload model from disk\n",
    "# model = tf.keras.models.load_model(f\"{MODEL_DIR / MODEL_NAME}\")\n",
    "model = tf.keras.models.load_model(f\"../models/cvae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(test_dataset.take(1)))\n",
    "reconstructed = model.predict(sample)\n",
    "beatbrain.display.show_spec(\n",
    "    utils.denormalize_spectrogram(sample[0, ..., 0].numpy()), title=\"Original\"\n",
    ")\n",
    "plt.show()\n",
    "beatbrain.display.show_spec(\n",
    "    utils.denormalize_spectrogram(model(sample)[0, ..., 0].numpy()),\n",
    "    title=\"Reconstructed\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Unconditioned Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_TO_GENERATE = 16\n",
    "INTERPOLATION_POINTS = 9\n",
    "OUTPUT_DIR = Path(\"../data/output/images\")\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[EXAMPLES_TO_GENERATE, LATENT_DIM]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(train_dataset.take(1))\n",
    "beatbrain.display.show_spec(utils.denormalize_spectrogram(sample[0, ..., 0]), title=\"Orginal\")\n",
    "plt.show()\n",
    "sns.distplot(train_dataset.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(train_dataset)\n",
    "beatbrain.display.show_spec(utils.denormalize_spectrogram(model(sample)[0, ..., 0].numpy()), title=\"Predicted\")\n",
    "plt.show()\n",
    "sns.distplot(model(train_dataset).numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 4096\n",
    "HOP_LENGTH = 256\n",
    "SAMPLE_RATE = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_recon = utils.spectrogram_to_audio(sample[0, ..., 0], denormalize=True, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(sample_recon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_recon = utils.spectrogram_to_audio(prediction[0, ..., 0], denormalize=True, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(prediction_recon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(decoder, epoch, test_input):\n",
    "    num_plots = math.ceil(math.sqrt(len(test_input)))\n",
    "    predictions = sample(LATENT_DIM, decoder, eps=test_input)\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    for i, pred in enumerate(predictions):\n",
    "        plt.subplot(num_plots, num_plots, i + 1)\n",
    "        plt.imshow(pred[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        plt.axis('off')\n",
    "        output_dir = os.path.join(OUTPUT_DIR, 'progress', str(i))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        image = Image.fromarray(pred[:, :, 0].numpy(), mode='F')\n",
    "#         image.save(os.path.join(output_dir, f\"epoch_{epoch}.tiff\"))\n",
    "        image.save(os.path.join(output_dir, f\"spec.tiff\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import librosa\n",
    "\n",
    "SR = 32768\n",
    "N_FFT = 4096\n",
    "N_MELS = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 5\n",
    "A = \"../data/fma/audio/000002.mp3\"\n",
    "B = \"../data/fma/audio/000005.mp3\"\n",
    "\n",
    "interp_dir = Path(f\"interpolation/{int(time())}\")\n",
    "interp_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "x, _ = librosa.load(A, sr=SR, duration=DURATION)\n",
    "y, _ = librosa.load(B, sr=SR, duration=DURATION)\n",
    "x = librosa.feature.melspectrogram(x, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "y = librosa.feature.melspectrogram(y, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "x, y = x[0, None], y[None, :, None]\n",
    "print(x.shape)\n",
    "x_mean, x_logvar = model.encode(x)\n",
    "y_mean, y_logvar = model.encode(y)\n",
    "\n",
    "# Reconstruction\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "x_recon = model.sample(model.reparameterize(x_mean, x_logvar))\n",
    "plt.imshow(x_recon[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Interpolation\n",
    "fractions = np.linspace(0, 1, num=INTERPOLATION_POINTS)[:, None]\n",
    "means = (x_mean * (1 - fractions)) + (y_mean * fractions)  # Interpolated latent vectors\n",
    "logvars = (x_logvar * (1 - fractions)) + (y_logvar * fractions)  # Interpolated latent vectors\n",
    "points = model.reparameterize(means, logvars)\n",
    "interpolated = model.sample(points)\n",
    "\n",
    "num_plots = math.ceil(math.sqrt(INTERPOLATION_POINTS))\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace=0, wspace=0.03)\n",
    "for i, pred in enumerate(interpolated):\n",
    "    Image.fromarray(pred[:, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'{i}.tiff'))\n",
    "    plt.subplot(num_plots, num_plots, i + 1)\n",
    "    if i == 0:\n",
    "        Image.fromarray(x[0, :, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'a.tiff'))\n",
    "        plt.imshow(x[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    elif i == INTERPOLATION_POINTS - 1:\n",
    "        Image.fromarray(y[0, :, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'b.tiff'))\n",
    "        plt.imshow(y[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    else:\n",
    "        plt.imshow(pred[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig(interp_dir.joinpath('interpolation.png'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
