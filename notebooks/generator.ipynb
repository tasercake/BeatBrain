{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# misc\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# scientific\n",
    "import numpy as np\n",
    "import beatbrain\n",
    "from beatbrain import utils\n",
    "\n",
    "# visualization\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Sequential, Input, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    MaxPool2D,\n",
    "    AveragePooling2D,\n",
    "    Dense,\n",
    "    Lambda,\n",
    "    Reshape,\n",
    "    Flatten,\n",
    "    Layer,\n",
    "    concatenate,\n",
    "    Add,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    Callback,\n",
    "    TensorBoard,\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TerminateOnNaN,\n",
    "    CSVLogger,\n",
    "    LambdaCallback,\n",
    ")\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "DATA_ROOT = Path(\"../data/fma/image\")\n",
    "IMAGE_DIMS = [512, 640, 1]\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input type(s) in \u001b[33m'/media/data/beatbrain_data/fma/image/train'\u001b[39m...\n",
      "Determined input type to be \u001b[36m'IMAGE'\u001b[39m\n",
      "Checking input type(s) in \u001b[33m'/media/data/beatbrain_data/fma/image/val'\u001b[39m...\n",
      "Determined input type to be \u001b[36m'IMAGE'\u001b[39m\n",
      "Checking input type(s) in \u001b[33m'/media/data/beatbrain_data/fma/image/test'\u001b[39m...\n",
      "Determined input type to be \u001b[36m'IMAGE'\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"train\", batch_size=BATCH_SIZE, parallel=False\n",
    ")\n",
    "val_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"val\", batch_size=BATCH_SIZE, parallel=False,\n",
    ")\n",
    "test_dataset = utils.load_dataset(\n",
    "    DATA_ROOT / \"test\", batch_size=1, parallel=False, shuffle_buffer=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + log2pi), axis=raxis\n",
    "    )\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample(latent_dim, decoder, eps=None):\n",
    "    if eps is None:\n",
    "        eps = tf.random.normal(shape=(100, latent_dim))\n",
    "    return decode(decoder, eps, apply_sigmoid=True)\n",
    "\n",
    "\n",
    "def encode(encoder, x):\n",
    "    inference = encoder(x)\n",
    "    mean, logvar = tf.split(inference, num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "\n",
    "def reparameterize(mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "\n",
    "def decode(decoder, z, apply_sigmoid=False):\n",
    "    logits = decoder(z)\n",
    "    if apply_sigmoid:\n",
    "        probs = tf.sigmoid(logits)\n",
    "        return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layers\n",
    "class NormConv2D(Layer):\n",
    "    \"\"\"\n",
    "    Batch-normalized, ReLU-activated convolution or transpose convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size, transpose=False):\n",
    "        self._kernel_size = kernel_size\n",
    "        self._filters = filters\n",
    "        self._transpose = transpose\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        conv_layer = Conv2DTranspose if self._transpose else Conv2D\n",
    "        self._model = Sequential([\n",
    "            conv_layer(self._filters, self._kernel_size, padding=\"SAME\",),\n",
    "            BatchNormalization(),\n",
    "            ReLU(),\n",
    "        ])\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self._model.compute_output_shape(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"filters\": self._filters,\n",
    "            \"kernel_size\": self._kernel_size,\n",
    "            \"transpose\": self._transpose,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class Inception2D(Layer):\n",
    "    def __init__(self, filters, transpose=False):\n",
    "        self._filters = filters\n",
    "        self._transpose = transpose\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        filters = self._filters\n",
    "        inputs = Input(shape=input_shape[1:])\n",
    "        bottleneck = NormConv2D(filters, 1, transpose=self._transpose)(inputs)\n",
    "        conv1 = NormConv2D(filters, 1, transpose=self._transpose)(bottleneck)\n",
    "        conv3 = NormConv2D(filters, 3, transpose=self._transpose)(bottleneck)\n",
    "        conv5 = NormConv2D(filters, 5, transpose=self._transpose)(bottleneck)\n",
    "        conv7 = NormConv2D(filters, 7, transpose=self._transpose)(bottleneck)\n",
    "        pool3 = MaxPool2D(pool_size=3, strides=1, padding=\"SAME\")(inputs)\n",
    "        pool5 = MaxPool2D(pool_size=5, strides=1, padding=\"SAME\")(inputs)\n",
    "        merged = Add()([conv1, conv3, conv5, conv7, pool3, pool5])\n",
    "        self._model = Model(inputs=inputs, outputs=merged)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self._model.compute_output_shape(input_shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"filters\": self._filters,\n",
    "            \"transpose\": self._transpose,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class DownSample2D(Layer):\n",
    "    def __init__(self, filters, pool_kernel_size):\n",
    "        self._filters = filters\n",
    "        self._pool_kernel_size = pool_kernel_size\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._model = Sequential(\n",
    "            [\n",
    "                AveragePooling2D(self._pool_kernel_size),\n",
    "                Conv2D(self._filters, 1),\n",
    "                BatchNormalization(),\n",
    "                ReLU(),\n",
    "            ],\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self._model.compute_output_shape(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"filters\": self._filters,\n",
    "            \"pool_kernel_size\": self._pool_kernel_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class UpSample2D(Layer):\n",
    "    def __init__(self, filters, pool_kernel_size):\n",
    "        self._filters = filters\n",
    "        self._pool_kernel_size = pool_kernel_size\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._model = Sequential(\n",
    "            [\n",
    "                Conv2DTranspose(self._filters, 1, strides=self._pool_kernel_size),\n",
    "                BatchNormalization(),\n",
    "                ReLU(),\n",
    "            ],\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self._model.compute_output_shape(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"filters\": self._filters,\n",
    "            \"pool_kernel_size\": self._pool_kernel_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class ConvBlock2D(Layer):\n",
    "    def __init__(self, filters, repeat, use_inception=True, transpose=False):\n",
    "        self._filters = filters\n",
    "        self._repeat = repeat\n",
    "        self._use_inception = use_inception\n",
    "        self._transpose = transpose\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self._use_inception:\n",
    "            layers = [Inception2D(self._filters, transpose=self._transpose) for i in range(self._repeat)]\n",
    "        else:\n",
    "            layers = [NormConv2D(self._filters, 3, transpose=self._transpose) for i in range(self._repeat)]\n",
    "        self._model = Sequential(layers)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self._model.compute_output_shape(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            \"filters\": self._filters,\n",
    "            \"repeat\": self._repeat,\n",
    "            \"use_inception\": self._use_inception,\n",
    "            \"transpose\": self._transpose,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def build_encoder(input_shape, latent_dim, batch_size, repeat, use_inception):\n",
    "    def reparam(args):\n",
    "        z_mean, z_log_var = args\n",
    "        dim = tf.keras.backend.int_shape(z_mean)[1]\n",
    "        eps = tf.keras.backend.random_normal(shape=(batch_size, dim))\n",
    "        return eps * tf.exp(z_log_var * 0.5) + z_mean\n",
    "\n",
    "    encoder_input = Input(shape=input_shape, batch_size=batch_size, name=\"encoder_input\")\n",
    "    e = Conv2D(32, 1)(encoder_input)\n",
    "    e = ConvBlock2D(32, repeat, use_inception=use_inception, transpose=False)(e)\n",
    "    e = DownSample2D(64, 4)(e)\n",
    "    e = ConvBlock2D(64, repeat, use_inception=use_inception, transpose=False)(e)\n",
    "    e = DownSample2D(128, 4)(e)\n",
    "    e = ConvBlock2D(128, repeat, use_inception=use_inception, transpose=False)(e)\n",
    "    e = DownSample2D(256, 2)(e)\n",
    "    e = ConvBlock2D(256, repeat, use_inception=use_inception, transpose=False)(e)\n",
    "    e = AveragePooling2D(8)(e)\n",
    "    e = Flatten()(e)\n",
    "    z_mean = Dense(latent_dim, name=\"z_mean\")(e)\n",
    "    z_log_var = Dense(latent_dim, name=\"z_log_var\")(e)\n",
    "    z = Lambda(reparam, output_shape=(latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
    "    encoder = Model(inputs=encoder_input, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder_input, encoder\n",
    "\n",
    "\n",
    "def build_decoder(latent_dim, output_shape, batch_size, repeat, use_inception):\n",
    "    decoder_input = Input(shape=latent_dim, batch_size=batch_size, name=\"decoder_input\")\n",
    "    start_shape = [\n",
    "        batch_size,\n",
    "        output_shape[0] // 32,\n",
    "        output_shape[1] // 32,\n",
    "        output_shape[2],\n",
    "    ]\n",
    "    print(f\"Start shape: {start_shape}\")\n",
    "    d = Dense(\n",
    "        start_shape[1] * start_shape[2] * start_shape[3],\n",
    "        activation=\"relu\",\n",
    "    )(decoder_input)\n",
    "    d = Reshape(\n",
    "        target_shape=(\n",
    "            start_shape[1],\n",
    "            start_shape[2],\n",
    "            start_shape[3],\n",
    "        )\n",
    "    )(d)\n",
    "    d = ConvBlock2D(256, repeat, use_inception, DecoderConv2D)(d)\n",
    "    d = UpSample2D(128, 2)(d)\n",
    "    d = ConvBlock2D(128, repeat, use_inception, DecoderConv2D)(d)\n",
    "    d = UpSample2D(64, 4)(d)\n",
    "    d = ConvBlock2D(64, repeat, use_inception, DecoderConv2D)(d)\n",
    "    d = UpSample2D(32, 4)(d)\n",
    "    d = ConvBlock2D(32, repeat, use_inception, DecoderConv2D)(d)\n",
    "    d = Conv2DTranspose(1, 1)(d)\n",
    "    d = ReLU(1.0)(d)  # Limit max value or no? Maybe use sigmoid instead?\n",
    "    decoder = Model(inputs=decoder_input, outputs=d, name=\"decoder\")\n",
    "    return decoder_input, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def build_cvae(\n",
    "    latent_dim,\n",
    "    input_shape,\n",
    "    start_filters=32,\n",
    "    num_conv=3,\n",
    "    num_inception=3,\n",
    "    num_deconv=3,\n",
    "    repeat=2,\n",
    "    use_inception=True,\n",
    "    batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "):\n",
    "    encoder_input, encoder = build_encoder(input_shape, latent_dim, batch_size, repeat, use_inception)\n",
    "    decoder_input, decoder = build_decoder(latent_dim, input_shape, batch_size, repeat, use_inception)\n",
    "\n",
    "    z_mean, z_log_var, z = encoder(encoder_input)\n",
    "    decoder_output = decoder(z)\n",
    "    model = Model(encoder_input, decoder_output, name=\"vae\")\n",
    "\n",
    "    print(f\"Encoder input: {encoder_input.shape}\")\n",
    "    print(f\"Decoder output: {decoder_output.shape}\")\n",
    "    assert encoder_input.shape == decoder_output.shape\n",
    "    reconstruction_loss = tf.losses.mse(encoder_input, decoder_output)\n",
    "    reconstruction_loss = tf.reduce_sum(reconstruction_loss, axis=[1, 2])\n",
    "    logpz = log_normal_pdf(z, 0.0, 0.0)\n",
    "    logqz_x = log_normal_pdf(z, z_mean, z_log_var)\n",
    "    kl_loss = logqz_x - logpz\n",
    "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    model.add_loss(vae_loss)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=lambda yt, yp: vae_loss)\n",
    "    return model, encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Model Output, and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LATENT_DIM = 256\n",
    "EPOCHS = 50\n",
    "NUM_CONV = 2\n",
    "NUM_INCEPTION = 3\n",
    "NUM_DECONV = 5\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# Outputs\n",
    "MODEL_NAME = \"cvae_2d_inception-facevae\"\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "LOG_DIR = Path(\"../logs\") / MODEL_NAME\n",
    "LOG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "LOG_FREQUENCY = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class VisualizeCallback(Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        log_dir,\n",
    "        latent_dim,\n",
    "        validation_data,\n",
    "        n_examples=4,\n",
    "        random_vectors=None,\n",
    "        heatmap=True,\n",
    "        frequency=\"epoch\",\n",
    "        verbose=False,\n",
    "    ):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_examples = n_examples\n",
    "        self.cmap = \"magma\" if heatmap else \"Greys\"\n",
    "        self.frequency = frequency\n",
    "        self.verbose = verbose\n",
    "        self.total_batch = 0\n",
    "        self.random_vectors = random_vectors or tf.random.normal(\n",
    "            shape=[n_examples, latent_dim]\n",
    "        )\n",
    "        self.fig = plt.figure()\n",
    "        self.samples = list(validation_data.unbatch().take(self.n_examples))\n",
    "\n",
    "        self.recon_raw = self.log_dir / \"raw\" / \"reconstructed\"\n",
    "        self.recon_png = self.log_dir / \"png\" / \"reconstructed\"\n",
    "        self.gen_raw = self.log_dir / \"raw\" / \"generated\"\n",
    "        self.gen_png = self.log_dir / \"png\" / \"generated\"\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.recon_raw.mkdir(exist_ok=True, parents=True)\n",
    "        self.recon_png.mkdir(exist_ok=True, parents=True)\n",
    "        self.gen_raw.mkdir(exist_ok=True, parents=True)\n",
    "        self.gen_png.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def _visualize_reconstruction(self, batch=None, epoch=None):\n",
    "        assert (batch is not None) or (epoch is not None)\n",
    "        fig = plt.figure(self.fig.number)\n",
    "        fig.set_size_inches(9, 4)\n",
    "        for i, sample in enumerate(self.samples):\n",
    "            fig.add_subplot(121)\n",
    "            sample = sample[None, :]\n",
    "            beatbrain.display.show_spec(\n",
    "                utils.denormalize_spectrogram(sample[0, ..., 0].numpy()),\n",
    "                title=\"Original\",\n",
    "                cmap=self.cmap,\n",
    "            )\n",
    "            fig.add_subplot(122)\n",
    "            reconstructed = self.model(sample)\n",
    "            beatbrain.display.show_spec(\n",
    "                utils.denormalize_spectrogram(reconstructed[0, ..., 0].numpy()),\n",
    "                title=\"Reconstructed\",\n",
    "                cmap=self.cmap,\n",
    "            )\n",
    "            fig.tight_layout()\n",
    "            title = f\"recon_{i + 1}@{'epoch' if epoch else 'batch'}_{epoch or batch}\"\n",
    "            fig.suptitle(title)\n",
    "            fig.savefig(self.recon_png / f\"{title}.png\")\n",
    "            utils.save_image(\n",
    "                reconstructed[0, ..., 0], self.recon_raw / f\"{title}.exr\",\n",
    "            )\n",
    "            fig.clear()\n",
    "\n",
    "    def _visualize_generation(self, batch=None, epoch=None):\n",
    "        assert (batch is not None) or (epoch is not None)\n",
    "        decoder = self.model.get_layer(\"decoder\")\n",
    "        generated = decoder(self.random_vectors)\n",
    "        fig = plt.figure(self.fig.number)\n",
    "        fig.set_size_inches(5, 4)\n",
    "        for i, gen in enumerate(generated):\n",
    "            gen = gen[None, :]\n",
    "            title = f\"gen_{i + 1}@{'epoch' if epoch else 'batch'}_{epoch or batch}\"\n",
    "            beatbrain.display.show_spec(\n",
    "                utils.denormalize_spectrogram(gen[0, ..., 0].numpy()),\n",
    "                title=title,\n",
    "                cmap=self.cmap,\n",
    "            )\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(self.gen_png / f\"{title}.png\")\n",
    "            utils.save_image(gen[0, ..., 0], self.gen_raw / f\"{title}.exr\")\n",
    "            fig.clear()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if self.frequency == \"epoch\":\n",
    "            self._visualize_reconstruction(epoch=epoch)\n",
    "            self._visualize_generation(epoch=epoch)\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        if isinstance(self.frequency, int) and (self.total_batch % self.frequency == 0):\n",
    "            self._visualize_reconstruction(batch=self.total_batch)\n",
    "            self._visualize_generation(batch=self.total_batch)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.total_batch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=LOG_DIR, update_freq=LOG_FREQUENCY, profile_batch=0,)\n",
    "reduce_lr = ReduceLROnPlateau(patience=2, factor=0.1, min_lr=1e-6, verbose=1,)\n",
    "early_stop = EarlyStopping(patience=5, verbose=1,)\n",
    "model_saver = ModelCheckpoint(\n",
    "    str(MODEL_DIR / MODEL_NAME), save_best_only=True, verbose=1,\n",
    ")\n",
    "visualizer = VisualizeCallback(\n",
    "    LOG_DIR, LATENT_DIM, val_dataset, frequency=LOG_FREQUENCY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on FMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start shape: [1, 16, 20, 1]\n",
      "Encoder input: (1, 512, 640, 1)\n",
      "Decoder output: (1, 512, 640, 1)\n",
      "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "Model: \"vae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(1, 512, 640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(1, 256), (1, 256), 15390912    encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (1, 512, 640, 1)     14881921    encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_7 (TensorFlowOp [(1, 256)]           0           encoder[1][2]                    \n",
      "                                                                 encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_2 (TensorFlowOp [(1, 256)]           0           encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_6 (TensorFlowOp [(1, 256)]           0           encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow_5 (TensorFlowOp [(1, 256)]           0           tf_op_layer_sub_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_2 (TensorFlowOp [(1, 256)]           0           tf_op_layer_Neg_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_pow_4 (TensorFlowOp [(1, 256)]           0           tf_op_layer_sub_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_10 (TensorFlowO [(1, 256)]           0           tf_op_layer_pow_5[0][0]          \n",
      "                                                                 tf_op_layer_Exp_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_8 (TensorFlowOp [(1, 256)]           0           tf_op_layer_pow_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_12 (TensorFlowO [(1, 256)]           0           tf_op_layer_mul_10[0][0]         \n",
      "                                                                 encoder[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_10 (TensorFlowO [(1, 256)]           0           tf_op_layer_mul_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_13 (TensorFlowO [(1, 256)]           0           tf_op_layer_add_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_11 (TensorFlowO [(1, 256)]           0           tf_op_layer_add_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SquaredDifference_2 [(1, 512, 640, 1)]   0           decoder[1][0]                    \n",
      "                                                                 encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_11 (TensorFlowO [(1, 256)]           0           tf_op_layer_add_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_9 (TensorFlowOp [(1, 256)]           0           tf_op_layer_add_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_4 (TensorFlowO [(1, 512, 640)]      0           tf_op_layer_SquaredDifference_2[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_8 (TensorFlowOp [(1,)]               0           tf_op_layer_mul_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_7 (TensorFlowOp [(1,)]               0           tf_op_layer_mul_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_6 (TensorFlowOp [(1,)]               0           tf_op_layer_Mean_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_8 (TensorFlowOp [(1,)]               0           tf_op_layer_Sum_8[0][0]          \n",
      "                                                                 tf_op_layer_Sum_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_14 (TensorFlowO [(1,)]               0           tf_op_layer_Sum_6[0][0]          \n",
      "                                                                 tf_op_layer_sub_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_5 (TensorFlowO [()]                 0           tf_op_layer_add_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_2 (AddLoss)            ()                   0           tf_op_layer_Mean_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 30,272,833\n",
      "Trainable params: 30,252,289\n",
      "Non-trainable params: 20,544\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(1, 512, 640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (1, 512, 640, 32)    64          encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_block2d_108 (ConvBlock2D)  (1, 512, 640, 32)    175680      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "down_sample2d_42 (DownSample2D) (1, 128, 160, 64)    2368        conv_block2d_108[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_block2d_109 (ConvBlock2D)  (1, 128, 160, 64)    699520      down_sample2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "down_sample2d_43 (DownSample2D) (1, 32, 40, 128)     8832        conv_block2d_109[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_block2d_110 (ConvBlock2D)  (1, 32, 40, 128)     2791680     down_sample2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "down_sample2d_44 (DownSample2D) (1, 16, 20, 256)     34048       conv_block2d_110[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_block2d_111 (ConvBlock2D)  (1, 16, 20, 256)     11153920    down_sample2d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (1, 2, 2, 256)       0           conv_block2d_111[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (1, 1024)            0           average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (1, 256)             262400      flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (1, 256)             262400      flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (1, 256)             0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,390,912\n",
      "Trainable params: 15,380,416\n",
      "Non-trainable params: 10,496\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(1, 256)]                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (1, 320)                  82240     \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (1, 16, 20, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv_block2d_112 (ConvBlock2 (1, 16, 20, 256)          11088640  \n",
      "_________________________________________________________________\n",
      "up_sample2d_39 (UpSample2D)  (1, 32, 40, 128)          33408     \n",
      "_________________________________________________________________\n",
      "conv_block2d_113 (ConvBlock2 (1, 32, 40, 128)          2791680   \n",
      "_________________________________________________________________\n",
      "up_sample2d_40 (UpSample2D)  (1, 128, 160, 64)         8512      \n",
      "_________________________________________________________________\n",
      "conv_block2d_114 (ConvBlock2 (1, 128, 160, 64)         699520    \n",
      "_________________________________________________________________\n",
      "up_sample2d_41 (UpSample2D)  (1, 512, 640, 32)         2208      \n",
      "_________________________________________________________________\n",
      "conv_block2d_115 (ConvBlock2 (1, 512, 640, 32)         175680    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (1, 512, 640, 1)          33        \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (1, 512, 640, 1)          0         \n",
      "=================================================================\n",
      "Total params: 14,881,921\n",
      "Trainable params: 14,871,873\n",
      "Non-trainable params: 10,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../models/cvae_2d_inception-facevae/assets\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_config() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-6ce8640146fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"model.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    905\u001b[0m       compat.as_bytes(constants.SAVED_MODEL_FILENAME_PB))\n\u001b[1;32m    906\u001b[0m   object_graph_proto = _serialize_object_graph(\n\u001b[0;32m--> 907\u001b[0;31m       saveable_view, asset_info.asset_index)\n\u001b[0m\u001b[1;32m    908\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_graph_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36m_serialize_object_graph\u001b[0;34m(saveable_view, asset_file_def_index)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_proto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m     \u001b[0m_write_object_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masset_file_def_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36m_write_object_proto\u001b[0;34m(obj, proto, asset_file_def_index)\u001b[0m\n\u001b[1;32m    696\u001b[0m           version=versions_pb2.VersionDef(\n\u001b[1;32m    697\u001b[0m               producer=1, min_consumer=1, bad_consumers=[]),\n\u001b[0;32m--> 698\u001b[0;31m           metadata=obj._tracking_metadata)\n\u001b[0m\u001b[1;32m    699\u001b[0m       \u001b[0;31m# pylint:enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregistered_type_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_tracking_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2412\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_tracking_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saved_model_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_extra_dependencies_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mtracking_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     return json.dumps(\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_properties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         default=serialization.get_json_type)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlist_extra_dependencies_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/util/serialization.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# e.g. optimizer, layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;31m# if obj is any numpy type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_config() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "model, encoder, decoder = build_cvae(\n",
    "    LATENT_DIM,\n",
    "    IMAGE_DIMS,\n",
    "    num_conv=NUM_CONV,\n",
    "    num_inception=NUM_INCEPTION,\n",
    "    num_deconv=NUM_DECONV,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "model.summary()\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "plot_model(model, to_file=str(LOG_DIR / \"model.png\"), expand_nested=True, show_shapes=True)\n",
    "tf.saved_model.save(model, str(MODEL_DIR / MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... get_config() missing 1 required positional argument: 'self'\n",
      "Epoch 1/50\n",
      "  187/38468 [..............................] - ETA: 10:31:20 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-021ce035fbbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_saver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# OR - Overfit model on a single sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mcurrent_trainable_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_trainable_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       outs, total_loss, output_losses, masks = (\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_trainable_state\u001b[0;34m(self, trainable_state)\u001b[0m\n\u001b[1;32m   2180\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_trainable_state\u001b[0;34m(self, trainable_state)\u001b[0m\n\u001b[1;32m   2180\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_trainable_state\u001b[0;34m(self, trainable_state)\u001b[0m\n\u001b[1;32m   2180\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_trainable_state\u001b[0;34m(self, trainable_state)\u001b[0m\n\u001b[1;32m   2180\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_trainable_state\u001b[0;34m(self, trainable_state)\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_layer_containers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trainable_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         hasattr(self.__class__, name)):\n\u001b[1;32m   2255\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         raise AttributeError(\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    430\u001b[0m                            ' Always start with this line.')\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# Keep track of metric instance created in subclassed model/layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         hasattr(self.__class__, name)):\n\u001b[1;32m   2255\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         raise AttributeError(\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         hasattr(self.__class__, name)):\n\u001b[1;32m   2255\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         raise AttributeError(\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    430\u001b[0m                            ' Always start with this line.')\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# Keep track of metric instance created in subclassed model/layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         hasattr(self.__class__, name)):\n\u001b[1;32m   2255\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         raise AttributeError(\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         hasattr(self.__class__, name)):\n\u001b[1;32m   2255\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         raise AttributeError(\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2322\u001b[0m     \u001b[0;31m# Skip the auto trackable from tf.Module to keep status quo. See the comment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m     \u001b[0;31m# at __delattr__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2324\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2326\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tensorboard, model_saver, reduce_lr, visualizer,],\n",
    "    validation_data=val_dataset,\n",
    ")\n",
    "# OR - Overfit model on a single sample\n",
    "# single_sample = tf.data.Dataset.from_tensor_slices(list(train_dataset.take(1)))\n",
    "# model.fit_generator(\n",
    "#     single_sample,\n",
    "#     epochs=400,\n",
    "#     callbacks=[VisualizeCallback(LOG_DIR, LATENT_DIM, single_sample, frequency=\"epoch\"),],\n",
    "#     validation_data=single_sample,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(train_images, _), (val_images, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "val_images = val_images.reshape(val_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "train_images /= 255.0\n",
    "val_images /= 255.0\n",
    "mnist_train = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_images).shuffle(50000).batch(BATCH_SIZE)\n",
    ")\n",
    "mnist_val = (\n",
    "    tf.data.Dataset.from_tensor_slices(val_images).shuffle(50000).batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "visualizer = VisualizeCallback(LOG_DIR, LATENT_DIM, mnist_val, frequency=100)\n",
    "\n",
    "# Define and train model\n",
    "model, encoder, decoder = build_cvae(\n",
    "    LATENT_DIM,\n",
    "    (28, 28, 1),\n",
    "    num_conv=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "model.fit_generator(\n",
    "    mnist_train,\n",
    "    epochs=200,\n",
    "    callbacks=[tensorboard, visualizer,],\n",
    "    validation_data=mnist_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - reload model from disk\n",
    "model = tf.keras.models.load_model(f\"{MODEL_DIR / MODEL_NAME}\")\n",
    "# model = tf.keras.models.load_model(f\"../models/cvae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(test_dataset.take(1)))\n",
    "reconstructed = model.predict(sample)\n",
    "beatbrain.display.show_spec(\n",
    "    utils.denormalize_spectrogram(sample[0, ..., 0].numpy()), title=\"Original\"\n",
    ")\n",
    "plt.show()\n",
    "beatbrain.display.show_spec(\n",
    "    utils.denormalize_spectrogram(model(sample)[0, ..., 0].numpy()),\n",
    "    title=\"Reconstructed\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Unconditioned Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_TO_GENERATE = 16\n",
    "INTERPOLATION_POINTS = 9\n",
    "OUTPUT_DIR = Path(\"../data/output/images\")\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[EXAMPLES_TO_GENERATE, LATENT_DIM]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(train_dataset.take(1))\n",
    "beatbrain.display.show_spec(utils.denormalize_spectrogram(sample[0, ..., 0]), title=\"Orginal\")\n",
    "plt.show()\n",
    "sns.distplot(train_dataset.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(train_dataset)\n",
    "beatbrain.display.show_spec(utils.denormalize_spectrogram(model(sample)[0, ..., 0].numpy()), title=\"Predicted\")\n",
    "plt.show()\n",
    "sns.distplot(model(train_dataset).numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 4096\n",
    "HOP_LENGTH = 256\n",
    "SAMPLE_RATE = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_recon = utils.spectrogram_to_audio(sample[0, ..., 0], denormalize=True, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(sample_recon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_recon = utils.spectrogram_to_audio(prediction[0, ..., 0], denormalize=True, n_fft=N_FFT, hop_length=HOP_LENGTH, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(prediction_recon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(decoder, epoch, test_input):\n",
    "    num_plots = math.ceil(math.sqrt(len(test_input)))\n",
    "    predictions = sample(LATENT_DIM, decoder, eps=test_input)\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    for i, pred in enumerate(predictions):\n",
    "        plt.subplot(num_plots, num_plots, i + 1)\n",
    "        plt.imshow(pred[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        plt.axis('off')\n",
    "        output_dir = os.path.join(OUTPUT_DIR, 'progress', str(i))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        image = Image.fromarray(pred[:, :, 0].numpy(), mode='F')\n",
    "#         image.save(os.path.join(output_dir, f\"epoch_{epoch}.tiff\"))\n",
    "        image.save(os.path.join(output_dir, f\"spec.tiff\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import librosa\n",
    "\n",
    "SR = 32768\n",
    "N_FFT = 4096\n",
    "N_MELS = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 5\n",
    "A = \"../data/fma/audio/000002.mp3\"\n",
    "B = \"../data/fma/audio/000005.mp3\"\n",
    "\n",
    "interp_dir = Path(f\"interpolation/{int(time())}\")\n",
    "interp_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "x, _ = librosa.load(A, sr=SR, duration=DURATION)\n",
    "y, _ = librosa.load(B, sr=SR, duration=DURATION)\n",
    "x = librosa.feature.melspectrogram(x, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "y = librosa.feature.melspectrogram(y, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "x, y = x[0, None], y[None, :, None]\n",
    "print(x.shape)\n",
    "x_mean, x_logvar = model.encode(x)\n",
    "y_mean, y_logvar = model.encode(y)\n",
    "\n",
    "# Reconstruction\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "x_recon = model.sample(model.reparameterize(x_mean, x_logvar))\n",
    "plt.imshow(x_recon[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Interpolation\n",
    "fractions = np.linspace(0, 1, num=INTERPOLATION_POINTS)[:, None]\n",
    "means = (x_mean * (1 - fractions)) + (y_mean * fractions)  # Interpolated latent vectors\n",
    "logvars = (x_logvar * (1 - fractions)) + (y_logvar * fractions)  # Interpolated latent vectors\n",
    "points = model.reparameterize(means, logvars)\n",
    "interpolated = model.sample(points)\n",
    "\n",
    "num_plots = math.ceil(math.sqrt(INTERPOLATION_POINTS))\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace=0, wspace=0.03)\n",
    "for i, pred in enumerate(interpolated):\n",
    "    Image.fromarray(pred[:, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'{i}.tiff'))\n",
    "    plt.subplot(num_plots, num_plots, i + 1)\n",
    "    if i == 0:\n",
    "        Image.fromarray(x[0, :, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'a.tiff'))\n",
    "        plt.imshow(x[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    elif i == INTERPOLATION_POINTS - 1:\n",
    "        Image.fromarray(y[0, :, :, 0].numpy(), mode='F').save(interp_dir.joinpath(f'b.tiff'))\n",
    "        plt.imshow(y[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    else:\n",
    "        plt.imshow(pred[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig(interp_dir.joinpath('interpolation.png'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
